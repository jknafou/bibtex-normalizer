@inproceedings{brown-etal-1988-statistical,
    url = {https://www.aclweb.org/anthology/C88-1016},
    year = {1988},
    booktitle = {{C}oling {B}udapest 1988 Volume 1: {I}nternational {C}onference on {C}omputational {L}inguistics},
    author = {Brown, P.  and
Cocke, J.  and
Della Pietra, S.  and
Della Pietra, V.  and
Jelinek, F.  and
Mercer, R.  and
Roossin, P.},
    title = {{A} {Statistical} {Approach} to {Language} {Translation}},
}

@article{brown-etal-1990-statistical,
    pages = {79--85},
    url = {https://www.aclweb.org/anthology/J90-2002},
    year = {1990},
    number = {2},
    volume = {16},
    journal = {Computational Linguistics},
    author = {Brown, Peter F.  and
Cocke, John  and
Della Pietra, Stephen A.  and
Della Pietra, Vincent J.  and
Jelinek, Fredrick  and
Lafferty, John D.  and
Mercer, Robert L.  and
Roossin, Paul S.},
    title = {{A} {Statistical} {Approach} to {Machine} {Translation}},
}

@article{brown-etal-1993-mathematics,
    pages = {263--311},
    url = {https://www.aclweb.org/anthology/J93-2003},
    year = {1993},
    number = {2},
    volume = {19},
    journal = {Computational Linguistics},
    author = {Brown, Peter F.  and
Della Pietra, Stephen A.  and
Della Pietra, Vincent J.  and
Mercer, Robert L.},
    title = {{The} {Mathematics} of {Statistical} {Machine} {Translation:} {Parameter} {Estimation}},
}

@inproceedings{papineni-etal-2002-bleu,
    pages = {311--318},
    doi = {10.3115/1073083.1073135},
    url = {https://www.aclweb.org/anthology/P02-1040},
    publisher = {Association for Computational Linguistics},
    address = {Philadelphia, Pennsylvania, USA},
    year = {2002},
    month = {jul},
    booktitle = {Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics},
    author = {Papineni, Kishore  and
Roukos, Salim  and
Ward, Todd  and
Zhu, Wei-Jing},
    title = {{B}leu: a {Method} for {Automatic} {Evaluation} of {Machine} {Translation}},
}

@inproceedings{koehn-etal-2003-statistical,
    pages = {127--133},
    url = {https://www.aclweb.org/anthology/N03-1017},
    year = {2003},
    booktitle = {Proceedings of the 2003 Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics},
    author = {Koehn, Philipp  and
Och, Franz J.  and
Marcu, Daniel},
    title = {{Statistical} {Phrase-Based} {Translation}},
}

@inproceedings{schwenk-etal-2006-continuous,
    pages = {723--730},
    url = {https://www.aclweb.org/anthology/P06-2093},
    publisher = {Association for Computational Linguistics},
    address = {Sydney, Australia},
    year = {2006},
    month = {jul},
    booktitle = {Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions},
    author = {Schwenk, Holger  and
Dechelotte, Daniel  and
Gauvain, Jean-Luc},
    title = {{Continuous} {Space} {Language} {Models} for {Statistical} {Machine} {Translation}},
}

@inproceedings{schwenk-2012-continuous,
    pages = {1071--1080},
    url = {https://www.aclweb.org/anthology/C12-2104},
    publisher = {The COLING 2012 Organizing Committee},
    address = {Mumbai, India},
    year = {2012},
    month = {dec},
    booktitle = {Proceedings of {COLING} 2012: Posters},
    author = {Schwenk, Holger},
    title = {{Continuous} {Space} {Translation} {Models} for {Phrase-Based} {Statistical} {Machine} {Translation}},
}

@inproceedings{kalchbrenner-blunsom-2013-recurrent,
    pages = {1700--1709},
    url = {https://www.aclweb.org/anthology/D13-1176},
    publisher = {Association for Computational Linguistics},
    address = {Seattle, Washington, USA},
    year = {2013},
    month = {oct},
    booktitle = {Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing},
    author = {Kalchbrenner, Nal  and
Blunsom, Phil},
    title = {{Recurrent} {Continuous} {Translation} {Models}},
}

@inproceedings{NIPS2014_a14ac55a,
    year = {2014},
    volume = {27},
    url = {https://proceedings.neurips.cc/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf},
    title = {{Sequence} to {Sequence} {Learning} with {Neural} {Networks}},
    publisher = {Curran Associates, Inc.},
    pages = {},
    editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K. Q. Weinberger},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
}

@inproceedings{luong-etal-2015-addressing,
    pages = {11--19},
    doi = {10.3115/v1/P15-1002},
    url = {https://www.aclweb.org/anthology/P15-1002},
    publisher = {Association for Computational Linguistics},
    address = {Beijing, China},
    year = {2015},
    month = {jul},
    booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
    author = {Luong, Thang  and
Sutskever, Ilya  and
Le, Quoc  and
Vinyals, Oriol  and
Zaremba, Wojciech},
    title = {{Addressing} the {Rare} {Word} {Problem} in {Neural} {Machine} {Translation}},
}

@inproceedings{wordpiece,
    doi = {10.1109/ICASSP.2012.6289079},
    pages = {5149-5152},
    number = {},
    volume = {},
    year = {2012},
    title = {{Japanese} and {Korean} {Voice} {Search}},
    booktitle = {2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
    author = {Schuster, Mike and Nakajima, Kaisuke},
}

@inproceedings{chitnis-denero-2015-variable,
    pages = {2088--2093},
    doi = {10.18653/v1/D15-1249},
    url = {https://www.aclweb.org/anthology/D15-1249},
    publisher = {Association for Computational Linguistics},
    address = {Lisbon, Portugal},
    year = {2015},
    month = {sep},
    booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
    author = {Chitnis, Rohan  and
DeNero, John},
    title = {{Variable-Length} {Word} {Encodings} for {Neural} {Translation} {Models}},
}

@article{bpe,
    numpages = {16},
    pages = {23–38},
    month = {feb},
    journal = {C Users J.},
    issn = {0898-9788},
    number = {2},
    volume = {12},
    address = {USA},
    publisher = {R \& D Publications, Inc.},
    issue_date = {Feb. 1994},
    year = {1994},
    title = {{A} {New} {Algorithm} for {Data} {Compression}},
    author = {Gage, Philip},
}

@inproceedings{sennrich-etal-2016-neural,
    pages = {1715--1725},
    doi = {10.18653/v1/P16-1162},
    url = {https://www.aclweb.org/anthology/P16-1162},
    publisher = {Association for Computational Linguistics},
    address = {Berlin, Germany},
    year = {2016},
    month = {aug},
    booktitle = {Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
    author = {Sennrich, Rico  and
Haddow, Barry  and
Birch, Alexandra},
    title = {{Neural} {Machine} {Translation} of {Rare} {Words} with {Subword} {Units}},
}

@article{gnmt,
    volume = {abs/1609.08144},
    journal = {CoRR},
    url = {http://arxiv.org/abs/1609.08144},
    year = {2016},
    author = {Yonghui Wu and Mike Schuster and Zhifeng Chen and Quoc V. Le and Mohammad Norouzi and Wolfgang Macherey and Maxim Krikun and Yuan Cao and Qin Gao and Klaus Macherey and Jeff Klingner and Apurva Shah and Melvin Johnson and Xiaobing Liu and Łukasz Kaiser and Stephan Gouws and Yoshikiyo Kato and Taku Kudo and Hideto Kazawa and Keith Stevens and George Kurian and Nishant Patil and Wei Wang and Cliff Young and Jason Smith and Jason Riesa and Alex Rudnick and Oriol Vinyals and Greg Corrado and Macduff Hughes and Jeffrey Dean},
    title = {{Google's} {Neural} {Machine} {Translation} {System:} {Bridging} the {Gap} {Between} {Human} and {Machine} {Translation}},
}

@inproceedings{kudo-2018-subword,
    abstract = {Subword units are an effective way to alleviate the open vocabulary problems in neural machine translation (NMT). While sentences are usually converted into unique subword sequences, subword segmentation is potentially ambiguous and multiple segmentations are possible even with the same vocabulary. The question addressed in this paper is whether it is possible to harness the segmentation ambiguity as a noise to improve the robustness of NMT. We present a simple regularization method, subword regularization, which trains the model with multiple subword segmentations probabilistically sampled during training. In addition, for better subword sampling, we propose a new subword segmentation algorithm based on a unigram language model. We experiment with multiple corpora and report consistent improvements especially on low resource and out-of-domain settings.},
    pages = {66--75},
    doi = {10.18653/v1/P18-1007},
    url = {https://www.aclweb.org/anthology/P18-1007},
    publisher = {Association for Computational Linguistics},
    address = {Melbourne, Australia},
    year = {2018},
    month = {jul},
    booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
    author = {Kudo, Taku},
    title = {{Subword} {Regularization:} {Improving} {Neural} {Network} {Translation} {Models} with {Multiple} {Subword} {Candidates}},
}

@inproceedings{kudo-richardson-2018-sentencepiece,
    abstract = {This paper describes SentencePiece, a language-independent subword tokenizer and detokenizer designed for Neural-based text processing, including Neural Machine Translation. It provides open-source C++ and Python implementations for subword units. While existing subword segmentation tools assume that the input is pre-tokenized into word sequences, SentencePiece can train subword models directly from raw sentences, which allows us to make a purely end-to-end and language independent system. We perform a validation experiment of NMT on English-Japanese machine translation, and find that it is possible to achieve comparable accuracy to direct subword training from raw sentences. We also compare the performance of subword training and segmentation with various configurations. SentencePiece is available under the Apache 2 license at \url{https://github.com/google/sentencepiece}.},
    pages = {66--71},
    doi = {10.18653/v1/D18-2012},
    url = {https://www.aclweb.org/anthology/D18-2012},
    publisher = {Association for Computational Linguistics},
    address = {Brussels, Belgium},
    year = {2018},
    month = {nov},
    booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
    author = {Kudo, Taku  and
Richardson, John},
    title = {{S}entence{P}iece: {A} {Simple} and {Language} {Independent} {Subword} {Tokenizer} and {Detokenizer} for {Neural} {Text} {Processing}},
}

@article{bahdanau2014neural,
    year = {2014},
    journal = {arXiv preprint arXiv:1409.0473},
    author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
    title = {{Neural} {Machine} {Translation} by {Jointly} {Learning} to {Align} and {Translate}},
}

@inproceedings{attention-is-all-you-need,
    year = {2017},
    volume = {30},
    url = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
    title = {{Attention} is {All} {You} {Need}},
    publisher = {Curran Associates, Inc.},
    pages = {},
    editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
}

@inproceedings{barrault-etal-2019-findings,
    abstract = {This paper presents the results of the premier shared task organized alongside the Conference on Machine Translation (WMT) 2019. Participants were asked to build machine translation systems for any of 18 language pairs, to be evaluated on a test set of news stories. The main metric for this task is human judgment of translation quality. The task was also opened up to additional test suites to probe specific aspects of translation.},
    pages = {1--61},
    doi = {10.18653/v1/W19-5301},
    url = {https://www.aclweb.org/anthology/W19-5301},
    publisher = {Association for Computational Linguistics},
    address = {Florence, Italy},
    year = {2019},
    month = {aug},
    booktitle = {Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)},
    author = {Barrault, Lo{\"\i}c  and
Bojar, Ond{\v{r}}ej  and
Costa-juss{\`a}, Marta R.  and
Federmann, Christian  and
Fishel, Mark  and
Graham, Yvette  and
Haddow, Barry  and
Huck, Matthias  and
Koehn, Philipp  and
Malmasi, Shervin  and
Monz, Christof  and
M{\"u}ller, Mathias  and
Pal, Santanu  and
Post, Matt  and
Zampieri, Marcos},
    title = {{Findings} of the {2019} {Conference} on {Machine} {Translation} ({WMT}19)},
}

@inproceedings{barrault-etal-2020-findings,
    abstract = {This paper presents the results of the news translation task and the similar language translation task, both organised alongside the Conference on Machine Translation (WMT) 2020. In the news task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting mainly of news stories. The task was also opened up to additional test suites to probe specific aspects of translation. In the similar language translation task, participants built machine translation systems for translating between closely related pairs of languages.},
    pages = {1--55},
    url = {https://www.aclweb.org/anthology/2020.wmt-1.1},
    publisher = {Association for Computational Linguistics},
    address = {Online},
    year = {2020},
    month = {nov},
    booktitle = {Proceedings of the Fifth Conference on Machine Translation},
    author = {Barrault, Lo{\"\i}c  and
Biesialska, Magdalena  and
Bojar, Ond{\v{r}}ej  and
Costa-juss{\`a}, Marta R.  and
Federmann, Christian  and
Graham, Yvette  and
Grundkiewicz, Roman  and
Haddow, Barry  and
Huck, Matthias  and
Joanis, Eric  and
Kocmi, Tom  and
Koehn, Philipp  and
Lo, Chi-kiu  and
Ljube{\v{s}}i{\'c}, Nikola  and
Monz, Christof  and
Morishita, Makoto  and
Nagata, Masaaki  and
Nakazawa, Toshiaki  and
Pal, Santanu  and
Post, Matt  and
Zampieri, Marcos},
    title = {{Findings} of the {2020} {Conference} on {Machine} {Translation} ({WMT}20)},
}

@inproceedings{bojar-etal-2018-findings,
    abstract = {This paper presents the results of the premier shared task organized alongside the Conference on Machine Translation (WMT) 2018. Participants were asked to build machine translation systems for any of 7 language pairs in both directions, to be evaluated on a test set of news stories. The main metric for this task is human judgment of translation quality. This year, we also opened up the task to additional test sets to probe specific aspects of translation.},
    pages = {272--303},
    doi = {10.18653/v1/W18-6401},
    url = {https://www.aclweb.org/anthology/W18-6401},
    publisher = {Association for Computational Linguistics},
    address = {Belgium, Brussels},
    year = {2018},
    month = {oct},
    booktitle = {Proceedings of the Third Conference on Machine Translation: Shared Task Papers},
    author = {Bojar, Ond{\v{r}}ej  and
Federmann, Christian  and
Fishel, Mark  and
Graham, Yvette  and
Haddow, Barry  and
Koehn, Philipp  and
Monz, Christof},
    title = {{Findings} of the {2018} {Conference} on {Machine} {Translation} ({WMT}18)},
}

@inproceedings{bawden-etal-2020-findings,
    abstract = {Machine translation of scientific abstracts and terminologies has the potential to support health professionals and biomedical researchers in some of their activities. In the fifth edition of the WMT Biomedical Task, we addressed a total of eight language pairs. Five language pairs were previously addressed in past editions of the shared task, namely, English/German, English/French, English/Spanish, English/Portuguese, and English/Chinese. Three additional languages pairs were also introduced this year: English/Russian, English/Italian, and English/Basque. The task addressed the evaluation of both scientific abstracts (all language pairs) and terminologies (English/Basque only). We received submissions from a total of 20 teams. For recurring language pairs, we observed an improvement in the translations in terms of automatic scores and qualitative evaluations, compared to previous years.},
    pages = {660--687},
    url = {https://www.aclweb.org/anthology/2020.wmt-1.76},
    publisher = {Association for Computational Linguistics},
    address = {Online},
    year = {2020},
    month = {nov},
    booktitle = {Proceedings of the Fifth Conference on Machine Translation},
    author = {Bawden, Rachel  and
Di Nunzio, Giorgio Maria  and
Grozea, Cristian  and
Jauregi Unanue, Inigo  and
Jimeno Yepes, Antonio  and
Mah, Nancy  and
Martinez, David  and
N{\'e}v{\'e}ol, Aur{\'e}lie  and
Neves, Mariana  and
Oronoz, Maite  and
Perez-de-Vi{\~n}aspre, Olatz  and
Piccardi, Massimo  and
Roller, Roland  and
Siu, Amy  and
Thomas, Philippe  and
Vezzani, Federica  and
Vicente Navarro, Maika  and
Wiemann, Dina  and
Yeganova, Lana},
    title = {{Findings} of the {WMT} {2020} {Biomedical} {Translation} {Shared} {Task:} {B}asque, {I}talian and {R}ussian as {New} {Additional} {Languages}},
}

@inproceedings{firat-etal-2016-multi,
    pages = {866--875},
    doi = {10.18653/v1/N16-1101},
    url = {https://www.aclweb.org/anthology/N16-1101},
    publisher = {Association for Computational Linguistics},
    address = {San Diego, California},
    year = {2016},
    month = {jun},
    booktitle = {Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
    author = {Firat, Orhan  and
Cho, Kyunghyun  and
Bengio, Yoshua},
    title = {{Multi-Way,} {Multilingual} {Neural} {Machine} {Translation} with a {Shared} {Attention} {Mechanism}},
}

@article{johnson-etal-2017-googles,
    abstract = {We propose a simple solution to use a single Neural Machine Translation (NMT) model to translate between multiple languages. Our solution requires no changes to the model architecture from a standard NMT system but instead introduces an artificial token at the beginning of the input sentence to specify the required target language. Using a shared wordpiece vocabulary, our approach enables Multilingual NMT systems using a single model. On the WMT{'}14 benchmarks, a single multilingual model achieves comparable performance for Englishâ†’French and surpasses state-of-theart results for Englishâ†’German. Similarly, a single multilingual model surpasses state-of-the-art results for Frenchâ†’English and Germanâ†’English on WMT{'}14 and WMT{'}15 benchmarks, respectively. On production corpora, multilingual models of up to twelve language pairs allow for better translation of many individual pairs. Our models can also learn to perform implicit bridging between language pairs never seen explicitly during training, showing that transfer learning and zero-shot translation is possible for neural translation. Finally, we show analyses that hints at a universal interlingua representation in our models and also show some interesting examples when mixing languages.},
    pages = {339--351},
    doi = {10.1162/tacl_a_00065},
    url = {https://www.aclweb.org/anthology/Q17-1024},
    year = {2017},
    volume = {5},
    journal = {Transactions of the Association for Computational Linguistics},
    author = {Johnson, Melvin  and
Schuster, Mike  and
Le, Quoc V.  and
Krikun, Maxim  and
Wu, Yonghui  and
Chen, Zhifeng  and
Thorat, Nikhil  and
Vi{\'e}gas, Fernanda  and
Wattenberg, Martin  and
Corrado, Greg  and
Hughes, Macduff  and
Dean, Jeffrey},
    title = {{G}oogle{'}s {Multilingual} {Neural} {Machine} {Translation} {System:} {Enabling} {Zero-Shot} {Translation}},
}

@article{lample2019cross,
    year = {2019},
    journal = {arXiv preprint arXiv:1901.07291},
    author = {Lample, Guillaume and Conneau, Alexis},
    title = {{Cross-lingual} {Language} {Model} {Pretraining}},
}

@article{m2m-100,
    bibsource = {dblp computer science bibliography, https://dblp.org},
    biburl = {https://dblp.org/rec/journals/corr/abs-2010-11125.bib},
    timestamp = {Mon, 26 Oct 2020 15:39:44 +0100},
    eprint = {2010.11125},
    archiveprefix = {arXiv},
    url = {https://arxiv.org/abs/2010.11125},
    year = {2020},
    volume = {abs/2010.11125},
    journal = {CoRR},
    title = {{Beyond} {English-Centric} {Multilingual} {Machine} {Translation}},
    author = {Angela Fan and
Shruti Bhosale and
Holger Schwenk and
Zhiyi Ma and
Ahmed El{-}Kishky and
Siddharth Goyal and
Mandeep Baines and
Onur Celebi and
Guillaume Wenzek and
Vishrav Chaudhary and
Naman Goyal and
Tom Birch and
Vitaliy Liptchinsky and
Sergey Edunov and
Edouard Grave and
Michael Auli and
Armand Joulin},
}

@article{brown-etal-1992-class,
    pages = {467--480},
    url = {https://www.aclweb.org/anthology/J92-4003},
    year = {1992},
    number = {4},
    volume = {18},
    journal = {Computational Linguistics},
    author = {Brown, Peter F.  and
Della Pietra, Vincent J.  and
deSouza, Peter V.  and
Lai, Jenifer C.  and
Mercer, Robert L.},
    title = {{Class-Based} \textit{n}-gram {Models} of {Natural} {Language}},
}

@article{bengio-2003,
    numpages = {19},
    pages = {1137–1155},
    month = {mar},
    journal = {J. Mach. Learn. Res.},
    abstract = {A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts.},
    issn = {1532-4435},
    number = {null},
    volume = {3},
    publisher = {JMLR.org},
    issue_date = {3/1/2003},
    year = {2003},
    title = {{A} {Neural} {Probabilistic} {Language} {Model}},
    author = {Bengio, Yoshua and Ducharme, R\'{e}jean and Vincent, Pascal and Janvin, Christian},
}

@inproceedings{morin-2005,
    note = {Reissued by PMLR on 30 March 2021.},
    url = {http://proceedings.mlr.press/r5/morin05a.html},
    pdf = {http://proceedings.mlr.press/r5/morin05a/morin05a.pdf},
    publisher = {PMLR},
    month = {06--08 Jan},
    series = {Proceedings of Machine Learning Research},
    volume = {R5},
    editor = {Cowell, Robert G. and Ghahramani, Zoubin},
    year = {2005},
    pages = {246--252},
    booktitle = {Proceedings of the Tenth International Workshop on Artificial Intelligence and Statistics},
    author = {Morin, Frederic and Bengio, Yoshua},
    title = {{Hierarchical} {Probabilistic} {Neural} {Network} {Language} {Model}},
}

@article{mnih2008scalable,
    publisher = {Citeseer},
    year = {2008},
    pages = {1081--1088},
    volume = {21},
    journal = {Advances in neural information processing systems},
    author = {Mnih, Andriy and Hinton, Geoffrey E},
    title = {{A} {Scalable} {Hierarchical} {Distributed} {Language} {Model}},
}

@inproceedings{collobert-2008,
    series = {ICML '08},
    location = {Helsinki, Finland},
    numpages = {8},
    pages = {160–167},
    booktitle = {Proceedings of the 25th International Conference on Machine Learning},
    abstract = {We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance.},
    doi = {10.1145/1390156.1390177},
    url = {https://doi.org/10.1145/1390156.1390177},
    address = {New York, NY, USA},
    publisher = {Association for Computing Machinery},
    isbn = {9781605582054},
    year = {2008},
    title = {{A} {Unified} {Architecture} for {Natural} {Language} {Processing:} {Deep} {Neural} {Networks} with {Multitask} {Learning}},
    author = {Collobert, Ronan and Weston, Jason},
}

@inproceedings{turian-etal-2010-word,
    pages = {384--394},
    url = {https://www.aclweb.org/anthology/P10-1040},
    publisher = {Association for Computational Linguistics},
    address = {Uppsala, Sweden},
    year = {2010},
    month = {jul},
    booktitle = {Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics},
    author = {Turian, Joseph  and
Ratinov, Lev-Arie  and
Bengio, Yoshua},
    title = {{Word} {Representations:} {A} {Simple} and {General} {Method} for {Semi-Supervised} {Learning}},
}

@article{mikolov2013efficient,
    year = {2013},
    journal = {arXiv preprint arXiv:1301.3781},
    author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
    title = {{Efficient} {Estimation} of {Word} {Representations} in {Vector} {Space}},
}

@inproceedings{mikolov-2013-w2v,
    series = {NIPS'13},
    location = {Lake Tahoe, Nevada},
    numpages = {9},
    pages = {3111–3119},
    booktitle = {Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2},
    abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling.An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of "Canada" and "Air" cannot be easily combined to obtain "Air Canada". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
    address = {Red Hook, NY, USA},
    publisher = {Curran Associates Inc.},
    year = {2013},
    title = {{Distributed} {Representations} of {Words} and {Phrases} and {Their} {Compositionality}},
    author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
}

@inproceedings{pennington2014glove,
    year = {2014},
    pages = {1532--1543},
    booktitle = {Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
    author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
    title = {{Glove:} {Global} {Vectors} for {Word} {Representation}},
}

@inproceedings{peters-etal-2018-deep,
    abstract = {We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.},
    pages = {2227--2237},
    doi = {10.18653/v1/N18-1202},
    url = {https://www.aclweb.org/anthology/N18-1202},
    publisher = {Association for Computational Linguistics},
    address = {New Orleans, Louisiana},
    year = {2018},
    month = {jun},
    booktitle = {Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
    author = {Peters, Matthew E.  and
Neumann, Mark  and
Iyyer, Mohit  and
Gardner, Matt  and
Clark, Christopher  and
Lee, Kenton  and
Zettlemoyer, Luke},
    title = {{Deep} {Contextualized} {Word} {Representations}},
}

@inproceedings{peters-etal-2017-semi,
    abstract = {Pre-trained word embeddings learned from unlabeled text have become a standard component of neural network architectures for NLP tasks. However, in most cases, the recurrent network that operates on word-level representations to produce context sensitive representations is trained on relatively little labeled data. In this paper, we demonstrate a general semi-supervised approach for adding pretrained context embeddings from bidirectional language models to NLP systems and apply it to sequence labeling tasks. We evaluate our model on two standard datasets for named entity recognition (NER) and chunking, and in both cases achieve state of the art results, surpassing previous systems that use other forms of transfer or joint learning with additional labeled data and task specific gazetteers.},
    pages = {1756--1765},
    doi = {10.18653/v1/P17-1161},
    url = {https://www.aclweb.org/anthology/P17-1161},
    publisher = {Association for Computational Linguistics},
    address = {Vancouver, Canada},
    year = {2017},
    month = {jul},
    booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
    author = {Peters, Matthew E.  and
Ammar, Waleed  and
Bhagavatula, Chandra  and
Power, Russell},
    title = {{Semi-supervised} {Sequence} {Tagging} with {Bidirectional} {Language} {Models}},
}

@article{devlin2018bert,
    year = {2018},
    journal = {arXiv preprint arXiv:1810.04805},
    author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
    title = {{Bert:} {Pre-training} of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
}

@inproceedings{wang-etal-2018-glue,
    abstract = {Human ability to understand language is \textit{general, flexible, and robust}. In contrast, most NLU models above the word level are designed for a specific task and struggle with out-of-domain data. If we aspire to develop models with understanding beyond the detection of superficial correspondences between inputs and outputs, then it is critical to develop a unified model that can execute a range of linguistic tasks across different domains. To facilitate research in this direction, we present the General Language Understanding Evaluation (GLUE, gluebenchmark.com): a benchmark of nine diverse NLU tasks, an auxiliary dataset for probing models for understanding of specific linguistic phenomena, and an online platform for evaluating and comparing models. For some benchmark tasks, training data is plentiful, but for others it is limited or does not match the genre of the test set. GLUE thus favors models that can represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge-transfer across tasks. While none of the datasets in GLUE were created from scratch for the benchmark, four of them feature privately-held test data, which is used to ensure that the benchmark is used fairly. We evaluate baselines that use ELMo (Peters et al., 2018), a powerful transfer learning technique, as well as state-of-the-art sentence representation models. The best models still achieve fairly low absolute scores. Analysis with our diagnostic dataset yields similarly weak performance over all phenomena tested, with some exceptions.},
    pages = {353--355},
    doi = {10.18653/v1/W18-5446},
    url = {https://www.aclweb.org/anthology/W18-5446},
    publisher = {Association for Computational Linguistics},
    address = {Brussels, Belgium},
    year = {2018},
    month = {nov},
    booktitle = {Proceedings of the 2018 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP}},
    author = {Wang, Alex  and
Singh, Amanpreet  and
Michael, Julian  and
Hill, Felix  and
Levy, Omer  and
Bowman, Samuel},
    title = {{GLUE}: {A} {Multi-Task} {Benchmark} and {Analysis} {Platform} for {Natural} {Language} {Understanding}},
}

@article{liu-2019-roberta,
    bibsource = {dblp computer science bibliography, https://dblp.org},
    biburl = {https://dblp.org/rec/journals/corr/abs-1907-11692.bib},
    timestamp = {Thu, 01 Aug 2019 08:59:33 +0200},
    eprint = {1907.11692},
    archiveprefix = {arXiv},
    url = {http://arxiv.org/abs/1907.11692},
    year = {2019},
    volume = {abs/1907.11692},
    journal = {CoRR},
    title = {{RoBERTa:} {A} {Robustly} {Optimized} {BERT} {Pretraining} {Approach}},
    author = {Yinhan Liu and
Myle Ott and
Naman Goyal and
Jingfei Du and
Mandar Joshi and
Danqi Chen and
Omer Levy and
Mike Lewis and
Luke Zettlemoyer and
Veselin Stoyanov},
}

@inproceedings{xlnet,
    year = {2019},
    volume = {32},
    url = {https://proceedings.neurips.cc/paper/2019/file/dc6a7e655d7e5840e66733e9ee67cc69-Paper.pdf},
    title = {{XLNet:} {Generalized} {Autoregressive} {Pretraining} for {Language} {Understanding}},
    publisher = {Curran Associates, Inc.},
    pages = {},
    editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
}

@article{Lee_2019,
    month = {Sep},
    year = {2019},
    editor = {Wren, JonathanEditor},
    author = {Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
    publisher = {Oxford University Press (OUP)},
    journal = {Bioinformatics},
    doi = {10.1093/bioinformatics/btz682},
    url = {http://dx.doi.org/10.1093/bioinformatics/btz682},
    issn = {1460-2059},
    title = {{BioBERT:} a {Pre-Trained} {Biomedical} {Language} {Representation} {Model} for {Biomedical} {Text} {Mining}},
}

@article{gu2020domain-specific,
    year = {2020},
    journal = {arXiv preprint arXiv:2007.15779},
    author = {Gu, Yu and Tinn, Robert and Cheng, Hao and Lucas, Michael and Usuyama, Naoto and Liu, Xiaodong and Naumann, Tristan and Gao, Jianfeng and Poon, Hoifung},
    title = {{Domain-specific} {Language} {Model} {Pretraining} for {Biomedical} {Natural} {Language} {Processing}},
}

@inproceedings{le-etal-2020-flaubert,
    isbn = {979-10-95546-34-4},
    language = {English},
    abstract = {Language models have become a key step to achieve state-of-the art results in many different Natural Language Processing (NLP) tasks. Leveraging the huge amount of unlabeled texts nowadays available, they provide an efficient way to pre-train continuous word representations that can be fine-tuned for a downstream task, along with their contextualization at the sentence level. This has been widely demonstrated for English using contextualized representations (Dai and Le, 2015; Peters et al., 2018; Howard and Ruder, 2018; Radford et al., 2018; Devlin et al., 2019; Yang et al., 2019b). In this paper, we introduce and share FlauBERT, a model learned on a very large and heterogeneous French corpus. Models of different sizes are trained using the new CNRS (French National Centre for Scientific Research) Jean Zay supercomputer. We apply our French language models to diverse NLP tasks (text classification, paraphrasing, natural language inference, parsing, word sense disambiguation) and show that most of the time they outperform other pre-training approaches. Different versions of FlauBERT as well as a unified evaluation protocol for the downstream tasks, called FLUE (French Language Understanding Evaluation), are shared to the research community for further reproducible experiments in French NLP.},
    pages = {2479--2490},
    url = {https://www.aclweb.org/anthology/2020.lrec-1.302},
    publisher = {European Language Resources Association},
    address = {Marseille, France},
    year = {2020},
    month = {may},
    booktitle = {Proceedings of the 12th Language Resources and Evaluation Conference},
    author = {Le, Hang  and
Vial, Lo{\"\i}c  and
Frej, Jibril  and
Segonne, Vincent  and
Coavoux, Maximin  and
Lecouteux, Benjamin  and
Allauzen, Alexandre  and
Crabb{\'e}, Benoit  and
Besacier, Laurent  and
Schwab, Didier},
    title = {{F}lau{BERT}: {Unsupervised} {Language} {Model} {Pre-training} for {F}rench},
}

@inproceedings{martin-etal-2020-camembert,
    abstract = {Pretrained language models are now ubiquitous in Natural Language Processing. Despite their success, most available models have either been trained on English data or on the concatenation of data in multiple languages. This makes practical use of such models {--}in all languages except English{--} very limited. In this paper, we investigate the feasibility of training monolingual Transformer-based language models for other languages, taking French as an example and evaluating our language models on part-of-speech tagging, dependency parsing, named entity recognition and natural language inference tasks. We show that the use of web crawled data is preferable to the use of Wikipedia data. More surprisingly, we show that a relatively small web crawled dataset (4GB) leads to results that are as good as those obtained using larger datasets (130+GB). Our best performing model CamemBERT reaches or improves the state of the art in all four downstream tasks.},
    pages = {7203--7219},
    doi = {10.18653/v1/2020.acl-main.645},
    url = {https://www.aclweb.org/anthology/2020.acl-main.645},
    publisher = {Association for Computational Linguistics},
    address = {Online},
    year = {2020},
    month = {jul},
    booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
    author = {Martin, Louis  and
Muller, Benjamin  and
Ortiz Su{\'a}rez, Pedro Javier  and
Dupont, Yoann  and
Romary, Laurent  and
de la Clergerie, {\'E}ric  and
Seddah, Djam{\'e}  and
Sagot, Beno{\^\i}t},
    title = {{C}amem{BERT}: a {Tasty} {F}rench {Language} {Model}},
}

@misc{isbister2021stop,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {2104.10441},
    year = {2021},
    author = {Tim Isbister and Fredrik Carlsson and Magnus Sahlgren},
    title = {{Should} {We} {Stop} {Training} {More} {Monolingual} {Models,} and {Simply} {Use} {Machine} {Translation} {Instead?}},
}

@inproceedings{duh-etal-2011-machine,
    pages = {429--433},
    url = {https://www.aclweb.org/anthology/P11-2075},
    publisher = {Association for Computational Linguistics},
    address = {Portland, Oregon, USA},
    year = {2011},
    month = {jun},
    booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
    author = {Duh, Kevin  and
Fujino, Akinori  and
Nagata, Masaaki},
    title = {{Is} {Machine} {Translation} {Ripe} for {Cross-Lingual} {Sentiment} {Classification?}},
}

@inproceedings{meng-etal-2012-cross,
    pages = {572--581},
    url = {https://www.aclweb.org/anthology/P12-1060},
    publisher = {Association for Computational Linguistics},
    address = {Jeju Island, Korea},
    year = {2012},
    month = {jul},
    booktitle = {Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
    author = {Meng, Xinfan  and
Wei, Furu  and
Liu, Xiaohua  and
Zhou, Ming  and
Xu, Ge  and
Wang, Houfeng},
    title = {{Cross-Lingual} {Mixture} {Model} for {Sentiment} {Classification}},
}

@article{teodoro-2020,
    eprint = {https://academic.oup.com/database/article-pdf/doi/10.1093/database/baaa026/33165294/baaa026.pdf},
    note = {baaa026},
    url = {https://doi.org/10.1093/database/baaa026},
    doi = {10.1093/database/baaa026},
    issn = {1758-0463},
    abstract = {In the UniProt Knowledgebase (UniProtKB), publications providing evidence for a specific protein annotation entry are organized across different categories, such as function, interaction and expression, based on the type of data they contain. To provide a systematic way of categorizing computationally mapped bibliographies in UniProt, we investigate a convolutional neural network (CNN) model to classify publications with accession annotations according to UniProtKB categories. The main challenge of categorizing publications at the accession annotation level is that the same publication can be annotated with multiple proteins and thus be associated with different category sets according to the evidence provided for the protein. We propose a model that divides the document into parts containing and not containing evidence for the protein annotation. Then, we use these parts to create different feature sets for each accession and feed them to separate layers of the network. The CNN model achieved a micro F1-score of 0.72 and a macro F1-score of 0.62, outperforming baseline models based on logistic regression and support vector machine by up to 22 and 18 percentage points, respectively. We believe that such an approach could be used to systematically categorize the computationally mapped bibliography in UniProtKB, which represents a significant set of the publications, and help curators to decide whether a publication is relevant for further curation for a protein accession.Database URL:https://goldorak.hesge.ch/bioexpclass/upclass/.},
    month = {05},
    year = {2020},
    volume = {2020},
    journal = {Database},
    title = {{UPCLASS:} a {Deep} {Learning-Based} {Classifier} for {UniProtKB} {Entry} {Publications}},
    author = {Teodoro, Douglas and Knafou, Julien and Naderi, Nona and Pasche, Emilie and Gobeill, Julien and Arighi, Cecilia N and Ruch, Patrick},
}

@inproceedings{copara-etal-2020-contextualized,
    abstract = {Named entity recognition (NER) is key for biomedical applications as it allows knowledge discovery in free text data. As entities are semantic phrases, their meaning is conditioned to the context to avoid ambiguity. In this work, we explore contextualized language models for NER in French biomedical text as part of the D{\'e}fi Fouille de Textes challenge. Our best approach achieved an F1 -measure of 66{\%} for symptoms and signs, and pathology categories, being top 1 for subtask 1. For anatomy, dose, exam, mode, moment, substance, treatment, and value categories, it achieved an F1 -measure of 75{\%} (subtask 2). If considered all categories, our model achieved the best result in the challenge, with an F1 -measure of 72{\%}. The use of an ensemble of neural language models proved to be very effective, improving a CRF baseline by up to 28{\%} and a single specialised language model by 4{\%}.},
    pages = {36--48},
    url = {https://www.aclweb.org/anthology/2020.jeptalnrecital-deft.4},
    publisher = {ATALA et AFCP},
    address = {Nancy, France},
    year = {2020},
    month = {6},
    booktitle = {Actes de la 6e conf{\'e}rence conjointe Journ{\'e}es d'{\'E}tudes sur la Parole (JEP, 33e {\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\'e}dition), Rencontre des {\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\'E}CITAL, 22e {\'e}dition). Atelier D{\'E}fi Fouille de Textes},
    author = {Copara, Jenny  and
Knafou, Julien  and
Naderi, Nona  and
Moro, Claudia  and
Ruch, Patrick  and
Teodoro, Douglas},
    title = {{Contextualized} {F}rench {Language} {Models} for {Biomedical} {Named} {Entity} {Recognition}},
}

@inproceedings{thompson-koehn-2019-vecalign,
    abstract = {We introduce Vecalign, a novel bilingual sentence alignment method which is linear in time and space with respect to the number of sentences being aligned and which requires only bilingual sentence embeddings. On a standard German{--}French test set, Vecalign outperforms the previous state-of-the-art method (which has quadratic time complexity and requires a machine translation system) by 5 F1 points. It substantially outperforms the popular Hunalign toolkit at recovering Bible verse alignments in medium- to low-resource language pairs, and it improves downstream MT quality by 1.7 and 1.6 BLEU in Sinhala-English and Nepali-English, respectively, compared to the Hunalign-based Paracrawl pipeline.},
    pages = {1342--1348},
    doi = {10.18653/v1/D19-1136},
    url = {https://www.aclweb.org/anthology/D19-1136},
    publisher = {Association for Computational Linguistics},
    address = {Hong Kong, China},
    year = {2019},
    month = {nov},
    booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
    author = {Thompson, Brian  and
Koehn, Philipp},
    title = {{V}ecalign: {Improved} {Sentence} {Alignment} in {Linear} {Time} and {Space}},
}

@article{knafou2023ensemble,
    publisher = {Springer},
    year = {2023},
    pages = {94},
    number = {1},
    volume = {12},
    journal = {Systematic Reviews},
    author = {Knafou, Julien and Haas, Quentin and Borissov, Nikolay and Counotte, Michel and Low, Nicola and Imeri, Hira and Ipekci, Aziz Mert and Buitrago-Garcia, Diana and Heron, Leonie and Amini, Poorya and others},
    title = {{Ensemble} of {Deep} {Learning} {Language} {Models} to {Support} the {Creation} of {Living} {Systematic} {Reviews} for the {COVID-19} {Literature}},
}

@article{naderi2021ensemble,
    publisher = {Frontiers Media SA},
    year = {2021},
    pages = {689803},
    volume = {6},
    journal = {Frontiers in research metrics and analytics},
    author = {Naderi, Nona and Knafou, Julien and Copara, Jenny and Ruch, Patrick and Teodoro, Douglas},
    title = {{Ensemble} of {Deep} {Masked} {Language} {Models} for {Effective} {Named} {Entity} {Recognition} in {Health} and {Life} {Science} {Corpora}},
}

@article{mottin2016nexta,
    publisher = {Oxford University Press},
    year = {2016},
    pages = {baw098},
    volume = {2016},
    journal = {Database},
    author = {Mottin, Luc and Gobeill, Julien and Pasche, Emilie and Michel, Pierre-Andr{\'e} and Cusin, Isabelle and Gaudet, Pascale and Ruch, Patrick},
    title = {{neXtA} {5:} {Accelerating} {Annotation} of {Articles} via {Automated} {Approaches} in {neXtProt}},
}

@article{ferdowsi2021classification,
    year = {2021},
    journal = {arXiv preprint arXiv:2110.15710},
    author = {Ferdowsi, Sohrab and Borissov, Nikolay and Knafou, Julien and Amini, Poorya and Teodoro, Douglas},
    title = {{Classification} of {Hierarchical} {Text} {Using} {Geometric} {Deep} {Learning:} the {Case} of {Clinical} {Trials} {Corpus}},
}

@article{4767370,
    doi = {10.1109/TPAMI.1983.4767370},
    pages = {179-190},
    number = {2},
    volume = {PAMI-5},
    year = {1983},
    title = {{A} {Maximum} {Likelihood} {Approach} to {Continuous} {Speech} {Recognition}},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    author = {Bahl, Lalit R. and Jelinek, Frederick and Mercer, Robert L.},
}

@article{MAYS1991517,
    abstract = {Some mistakes in spelling and typing produce correct words, such as typing “fig” when “fog” was intended. These errors are undetectable by traditional spelling correction techniques. In this paper we present a statistical technique capable of detecting and correcting some of these errors when they occur in sentences. Experimental results show that this technique is capable of detecting 76% of simple spelling errors and correcting 73%.},
    author = {Eric Mays and Fred J. Damerau and Robert L. Mercer},
    url = {https://www.sciencedirect.com/science/article/pii/030645739190066U},
    doi = {https://doi.org/10.1016/0306-4573(91)90066-U},
    issn = {0306-4573},
    year = {1991},
    pages = {517-522},
    number = {5},
    volume = {27},
    journal = {Information Processing \& Management},
    title = {{Context} {Based} {Spelling} {Correction}},
}

@misc{han2021pretrained,
    primaryclass = {cs.AI},
    archiveprefix = {arXiv},
    eprint = {2106.07139},
    year = {2021},
    author = {Xu Han and Zhengyan Zhang and Ning Ding and Yuxian Gu and Xiao Liu and Yuqi Huo and Jiezhong Qiu and Yuan Yao and Ao Zhang and Liang Zhang and Wentao Han and Minlie Huang and Qin Jin and Yanyan Lan and Yang Liu and Zhiyuan Liu and Zhiwu Lu and Xipeng Qiu and Ruihua Song and Jie Tang and Ji-Rong Wen and Jinhui Yuan and Wayne Xin Zhao and Jun Zhu},
    title = {{Pre-Trained} {Models:} {Past,} {Present} and {Future}},
}

@misc{zhu2015aligning,
    primaryclass = {cs.CV},
    archiveprefix = {arXiv},
    eprint = {1506.06724},
    year = {2015},
    author = {Yukun Zhu and Ryan Kiros and Richard Zemel and Ruslan Salakhutdinov and Raquel Urtasun and Antonio Torralba and Sanja Fidler},
    title = {{Aligning} {Books} and {Movies:} {Towards} {Story-like} {Visual} {Explanations} by {Watching} {Movies} and {Reading} {Books}},
}

@article{uniprot,
    eprint = {https://academic.oup.com/nar/article-pdf/51/D1/D523/48441158/gkac1052.pdf},
    url = {https://doi.org/10.1093/nar/gkac1052},
    doi = {10.1093/nar/gkac1052},
    issn = {0305-1048},
    abstract = {The aim of the UniProt Knowledgebase is to provide users with a comprehensive, high-quality and freely accessible set of protein sequences annotated with functional information. In this publication we describe enhancements made to our data processing pipeline and to our website to adapt to an ever-increasing information content. The number of sequences in UniProtKB has risen to over 227 million and we are working towards including a reference proteome for each taxonomic group. We continue to extract detailed annotations from the literature to update or create reviewed entries, while unreviewed entries are supplemented with annotations provided by automated systems using a variety of machine-learning techniques. In addition, the scientific community continues their contributions of publications and annotations to UniProt entries of their interest. Finally, we describe our new website (https://www.uniprot.org/), designed to enhance our users’ experience and make our data easily accessible to the research community. This interface includes access to AlphaFold structures for more than 85\\% of all entries as well as improved visualisations for subcellular localisation of proteins.},
    month = {11},
    year = {2022},
    pages = {D523-D531},
    number = {D1},
    volume = {51},
    journal = {Nucleic Acids Research},
    title = {{UniProt:} the {Universal} {Protein} {Knowledgebase} in {2023}},
    author = {The UniProt Consortium},
}

@misc{wang2020cord19,
    primaryclass = {cs.DL},
    archiveprefix = {arXiv},
    eprint = {2004.10706},
    year = {2020},
    author = {Lucy Lu Wang and Kyle Lo and Yoganand Chandrasekhar and Russell Reas and Jiangjiang Yang and Doug Burdick and Darrin Eide and Kathryn Funk and Yannis Katsis and Rodney Kinney and Yunyao Li and Ziyang Liu and William Merrill and Paul Mooney and Dewey Murdick and Devvret Rishi and Jerry Sheehan and Zhihong Shen and Brandon Stilson and Alex Wade and Kuansan Wang and Nancy Xin Ru Wang and Chris Wilhelm and Boya Xie and Douglas Raymond and Daniel S. Weld and Oren Etzioni and Sebastian Kohlmeier},
    title = {{CORD-19:} {The} {COVID-19} {Open} {Research} {Dataset}},
}

@article{10.1093/nar/gkaa952,
    eprint = {https://academic.oup.com/nar/article-pdf/49/D1/D1534/35364553/gkaa952.pdf},
    url = {https://doi.org/10.1093/nar/gkaa952},
    doi = {10.1093/nar/gkaa952},
    issn = {0305-1048},
    abstract = {Since the outbreak of the current pandemic in 2020, there has been a rapid growth of published articles on COVID-19 and SARS-CoV-2, with about 10 000 new articles added each month. This is causing an increasingly serious information overload, making it difficult for scientists, healthcare professionals and the general public to remain up to date on the latest SARS-CoV-2 and COVID-19 research. Hence, we developed LitCovid (https://www.ncbi.nlm.nih.gov/research/coronavirus/), a curated literature hub, to track up-to-date scientific information in PubMed. LitCovid is updated daily with newly identified relevant articles organized into curated categories. To support manual curation, advanced machine-learning and deep-learning algorithms have been developed, evaluated and integrated into the curation workflow. To the best of our knowledge, LitCovid is the first-of-its-kind COVID-19-specific literature resource, with all of its collected articles and curated data freely available. Since its release, LitCovid has been widely used, with millions of accesses by users worldwide for various information needs, such as evidence synthesis, drug discovery and text and data mining, among others.},
    month = {11},
    year = {2020},
    pages = {D1534-D1540},
    number = {D1},
    volume = {49},
    journal = {Nucleic Acids Research},
    title = {{LitCovid:} an {Open} {Database} of {COVID-19} {Literature}},
    author = {Chen, Qingyu and Allot, Alexis and Lu, Zhiyong},
}

@misc{coap,
    type = {Web Page},
    year = {2020},
    url = {https://ispmbern.github.io/covid-19/living-review/},
    title = {{Living} {Evidence} on {COVID-19}},
    author = {COVID-19 Open Access Project},
}

@article{DBLP:journals/corr/abs-2010-09885,
    bibsource = {dblp computer science bibliography, https://dblp.org},
    biburl = {https://dblp.org/rec/journals/corr/abs-2010-09885.bib},
    timestamp = {Thu, 14 Oct 2021 09:18:08 +0200},
    eprint = {2010.09885},
    eprinttype = {arXiv},
    url = {https://arxiv.org/abs/2010.09885},
    year = {2020},
    volume = {abs/2010.09885},
    journal = {CoRR},
    title = {{ChemBERTa:} {Large-Scale} {Self-Supervised} {Pretraining} for {Molecular} {Property} {Prediction}},
    author = {Seyone Chithrananda and
Gabriel Grand and
Bharath Ramsundar},
}

@article{Gu_2021,
    pages = {1–23},
    month = {oct},
    year = {2021},
    author = {Gu, Yu and Tinn, Robert and Cheng, Hao and Lucas, Michael and Usuyama, Naoto and Liu, Xiaodong and Naumann, Tristan and Gao, Jianfeng and Poon, Hoifung},
    publisher = {Association for Computing Machinery (ACM)},
    journal = {ACM Transactions on Computing for Healthcare},
    number = {1},
    doi = {10.1145/3458754},
    url = {http://dx.doi.org/10.1145/3458754},
    issn = {2637-8051},
    volume = {3},
    title = {{Domain-Specific} {Language} {Model} {Pretraining} for {Biomedical} {Natural} {Language} {Processing}},
}

@misc{cho2014properties,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {1409.1259},
    year = {2014},
    author = {Kyunghyun Cho and Bart van Merrienboer and Dzmitry Bahdanau and Yoshua Bengio},
    title = {{On} the {Properties} of {Neural} {Machine} {Translation:} {Encoder-Decoder} {Approaches}},
}

@misc{lin2017structured,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {1703.03130},
    year = {2017},
    author = {Zhouhan Lin and Minwei Feng and Cicero Nogueira dos Santos and Mo Yu and Bing Xiang and Bowen Zhou and Yoshua Bengio},
    title = {{A} {Structured} {Self-attentive} {Sentence} {Embedding}},
}

@misc{paulus2017deep,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {1705.04304},
    year = {2017},
    author = {Romain Paulus and Caiming Xiong and Richard Socher},
    title = {{A} {Deep} {Reinforced} {Model} for {Abstractive} {Summarization}},
}

@misc{britz2017massive,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {1703.03906},
    year = {2017},
    author = {Denny Britz and Anna Goldie and Minh-Thang Luong and Quoc Le},
    title = {{Massive} {Exploration} of {Neural} {Machine} {Translation} {Architectures}},
}

@misc{rajpurkar2016squad,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {1606.05250},
    year = {2016},
    author = {Pranav Rajpurkar and Jian Zhang and Konstantin Lopyrev and Percy Liang},
    title = {{SQuAD:} {100,000+} {Questions} for {Machine} {Comprehension} of {Text}},
}

@article{DBLP:journals/corr/abs-1905-00537,
    bibsource = {dblp computer science bibliography, https://dblp.org},
    biburl = {https://dblp.org/rec/journals/corr/abs-1905-00537.bib},
    timestamp = {Mon, 27 May 2019 13:15:00 +0200},
    eprint = {1905.00537},
    eprinttype = {arXiv},
    url = {http://arxiv.org/abs/1905.00537},
    year = {2019},
    volume = {abs/1905.00537},
    journal = {CoRR},
    title = {{SuperGLUE:} {A} {Stickier} {Benchmark} for {General-Purpose} {Language} {Understanding} {Systems}},
    author = {Alex Wang and
Yada Pruksachatkun and
Nikita Nangia and
Amanpreet Singh and
Julian Michael and
Felix Hill and
Omer Levy and
Samuel R. Bowman},
}

@inproceedings{peng-etal-2019-transfer,
    abstract = {Inspired by the success of the General Language Understanding Evaluation benchmark, we introduce the Biomedical Language Understanding Evaluation (BLUE) benchmark to facilitate research in the development of pre-training language representations in the biomedicine domain. The benchmark consists of five tasks with ten datasets that cover both biomedical and clinical texts with different dataset sizes and difficulties. We also evaluate several baselines based on BERT and ELMo and find that the BERT model pre-trained on PubMed abstracts and MIMIC-III clinical notes achieves the best results. We make the datasets, pre-trained models, and codes publicly available at \url{https://github.com/ncbi-nlp/BLUE_Benchmark}.},
    pages = {58--65},
    doi = {10.18653/v1/W19-5006},
    url = {https://aclanthology.org/W19-5006},
    publisher = {Association for Computational Linguistics},
    address = {Florence, Italy},
    year = {2019},
    month = {aug},
    booktitle = {Proceedings of the 18th BioNLP Workshop and Shared Task},
    editor = {Demner-Fushman, Dina  and
Cohen, Kevin Bretonnel  and
Ananiadou, Sophia  and
Tsujii, Junichi},
    author = {Peng, Yifan  and
Yan, Shankai  and
Lu, Zhiyong},
    title = {{Transfer} {Learning} in {Biomedical} {Natural} {Language} {Processing:} {An} {Evaluation} of {BERT} and {ELM}o on {Ten} {Benchmarking} {Datasets}},
}

@article{DBLP:journals/corr/ParikhT0U16,
    bibsource = {dblp computer science bibliography, https://dblp.org},
    biburl = {https://dblp.org/rec/journals/corr/ParikhT0U16.bib},
    timestamp = {Mon, 13 Aug 2018 16:49:14 +0200},
    eprint = {1606.01933},
    eprinttype = {arXiv},
    url = {http://arxiv.org/abs/1606.01933},
    year = {2016},
    volume = {abs/1606.01933},
    journal = {CoRR},
    title = {{A} {Decomposable} {Attention} {Model} for {Natural} {Language} {Inference}},
    author = {Ankur P. Parikh and
Oscar T{\"{a}}ckstr{\"{o}}m and
Dipanjan Das and
Jakob Uszkoreit},
}

@article{DBLP:journals/corr/ChengDL16,
    bibsource = {dblp computer science bibliography, https://dblp.org},
    biburl = {https://dblp.org/rec/journals/corr/ChengDL16.bib},
    timestamp = {Mon, 13 Aug 2018 16:48:39 +0200},
    eprint = {1601.06733},
    eprinttype = {arXiv},
    url = {http://arxiv.org/abs/1601.06733},
    year = {2016},
    volume = {abs/1601.06733},
    journal = {CoRR},
    title = {{Long} {Short-Term} {Memory-Networks} for {Machine} {Reading}},
    author = {Jianpeng Cheng and
Li Dong and
Mirella Lapata},
}

@misc{kingma2017adam,
    primaryclass = {cs.LG},
    archiveprefix = {arXiv},
    eprint = {1412.6980},
    year = {2017},
    author = {Diederik P. Kingma and Jimmy Ba},
    title = {{Adam:} {A} {Method} for {Stochastic} {Optimization}},
}

@misc{zellers2018swag,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {1808.05326},
    year = {2018},
    author = {Rowan Zellers and Yonatan Bisk and Roy Schwartz and Yejin Choi},
    title = {{SWAG:} {A} {Large-Scale} {Adversarial} {Dataset} for {Grounded} {Commonsense} {Inference}},
}

@misc{he2021deberta,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {2006.03654},
    year = {2021},
    author = {Pengcheng He and Xiaodong Liu and Jianfeng Gao and Weizhu Chen},
    title = {{DeBERTa:} {Decoding-enhanced} {BERT} with {Disentangled} {Attention}},
}

@misc{cañete2023spanish,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {2308.02976},
    year = {2023},
    author = {José Cañete and Gabriel Chaperon and Rodrigo Fuentes and Jou-Hui Ho and Hojin Kang and Jorge Pérez},
    title = {{Spanish} {Pre-trained} {BERT} {Model} and {Evaluation} {Data}},
}

@article{BERTIN,
    pages = {13--23},
    url = {http://journal.sepln.org/sepln/ojs/ojs/index.php/pln/article/view/6403},
    issn = {1989-7553},
    abstract = {The pre-training of large language models usually requires massive amounts of resources, both in terms of computation and data. Frequently used web sources such as Common Crawl might contain enough noise to make this pretraining sub-optimal. In this work, we experiment with different sampling methods from the Spanish version of mC4, and present a novel data-centric technique which we name perplexity sampling that enables the pre-training of language models in roughly half the amount of steps and using one fifth of the data. The resulting models are comparable to the current state-of-the-art, and even achieve better results for certain tasks. Our work is proof of the versatility of Transformers, and paves the way for small teams to train their models on a limited budget.},
    keywords = {},
    year = {2022},
    number = {0},
    volume = {68},
    journal = {Procesamiento del Lenguaje Natural},
    title = {{BERTIN:} {Efficient} {Pre-Training} of a {Spanish} {Language} {Model} {Using} {Perplexity} {Sampling}},
    author = {Javier De la Rosa and Eduardo G. Ponferrada and Manu Romero and Paulo Villegas and Pablo González de Prado Salas and María Grandury},
}

@inproceedings{souza2020bertimbau,
    isbn = {978-3-030-61377-8},
    pages = {403--417},
    address = {Cham},
    publisher = {Springer International Publishing},
    year = {2020},
    booktitle = {Intelligent Systems},
    title = {{BERTimbau:} {Pretrained} {BERT} {Models} for {Brazilian} {Portuguese}},
    editor = {Cerri, Ricardo and Prati, Ronaldo C.},
    author = {Souza, F{\'a}bio and Nogueira, Rodrigo and Lotufo, Roberto},
}

@article{joshi2022l3cubehind,
    year = {2022},
    journal = {arXiv preprint arXiv:2211.11418},
    author = {Joshi, Raviraj},
    title = {{L3Cube-HindBERT} and {DevBERT:} {Pre-Trained} {BERT} {Transformer} {Models} for {Devanagari} {Based} {Hindi} and {Marathi} {Languages}},
}

@inproceedings{OrtizSuarezSagotRomary2019,
    language = {en},
    abstract = {Common Crawl is a considerably large, heterogeneous multilingual corpus comprised of crawled documents from the internet, surpassing 20TB of data and distributed as a set of more than 50 thousand plain text files where each contains many documents written in a wide variety of languages. Even though each document has a metadata block associated to it, this data lacks any information about the language in which each document is written, making it extremely difficult to use Common Crawl for monolingual applications. We propose a general, highly parallel, multithreaded pipeline to clean and classify Common Crawl by language; we specifically design it so that it runs efficiently on medium to low resource infrastructures where I/O speeds are the main constraint. We develop the pipeline so that it can be easily reapplied to any kind of heterogeneous corpus and so that it can be parameterised to a wide range of infrastructures. We also distribute a 6.3TB version of Common Crawl, filtered, classified by language, shuffled at line level in order to avoid copyright issues, and ready to be used for NLP applications.},
    year = {2019},
    pages = {9 -- 16},
    url = {http://nbn-resolving.de/urn:nbn:de:bsz:mh39-90215},
    doi = {10.14618/ids-pub-9021},
    address = {Mannheim},
    publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},
    editor = {Piotr Bański and Adrien Barbaresi and Hanno Biber and Evelyn Breiteneder and Simon Clematide and Marc Kupietz and Harald L{\"u}ngen and Caroline Iliadi},
    series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-7) 2019. Cardiff, 22nd July 2019},
    title = {{Asynchronous} {Pipelines} for {Processing} {Huge} {Corpora} on {Medium} to {Low} {Resource} {Infrastructures}},
    author = {Pedro Javier {Ortiz Su{\'a}rez} and Beno{\^i}t Sagot and Laurent Romary},
}

@article{Cui_2021,
    pages = {3504–3514},
    year = {2021},
    author = {Cui, Yiming and Che, Wanxiang and Liu, Ting and Qin, Bing and Yang, Ziqing},
    publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
    journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
    doi = {10.1109/taslp.2021.3124365},
    url = {http://dx.doi.org/10.1109/TASLP.2021.3124365},
    issn = {2329-9304},
    volume = {29},
    title = {{Pre-Training} {With} {Whole} {Word} {Masking} for {Chinese} {BERT}},
}

@article{DBLP:journals/corr/abs-1911-02116,
    bibsource = {dblp computer science bibliography, https://dblp.org},
    biburl = {https://dblp.org/rec/journals/corr/abs-1911-02116.bib},
    timestamp = {Mon, 11 Nov 2019 18:38:09 +0100},
    eprint = {1911.02116},
    eprinttype = {arXiv},
    url = {http://arxiv.org/abs/1911.02116},
    year = {2019},
    volume = {abs/1911.02116},
    journal = {CoRR},
    title = {{Unsupervised} {Cross-lingual} {Representation} {Learning} at {Scale}},
    author = {Alexis Conneau and
Kartikay Khandelwal and
Naman Goyal and
Vishrav Chaudhary and
Guillaume Wenzek and
Francisco Guzm{\'{a}}n and
Edouard Grave and
Myle Ott and
Luke Zettlemoyer and
Veselin Stoyanov},
}

@misc{touchent2023camembertbio,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {2306.15550},
    year = {2023},
    author = {Rian Touchent and Laurent Romary and Eric de la Clergerie},
    title = {{CamemBERT-bio:} a {Tasty} {French} {Language} {Model} {Better} for {Your} {Health}},
}

@inproceedings{touchent:hal-04130187,
    hal_version = {v1},
    hal_id = {hal-04130187},
    keywords = {comptes rendus m{\'e}dicaux ; TAL clinique ; CamemBERT ; extraction d'information ; biom{\'e}dical ; reconnaissance d'entit{\'e}s nomm{\'e}es},
    year = {2023},
    pages = {323-334},
    publisher = {ATALA},
    editor = {Servan, Christophe and Vilnat, Anne},
    address = {Paris, France},
    booktitle = {18e  Conf{\'e}rence en Recherche d'Information et Applications \\ 16e Rencontres Jeunes Chercheurs en RI \\ 30e Conf{\'e}rence sur le Traitement Automatique des Langues Naturelles \\ 25e Rencontre des {\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues},
    url = {https://hal.science/hal-04130187},
    author = {Touchent, Rian and Romary, Laurent and De La Clergerie, Eric},
    title = {{CamemBERT-bio} {:} {Un} mod{\`e}le {De} {Langue} fran{\c {C}ais} {Savoureux} {Et} {Meilleur} {Pour} {La} sant{\'e}},
}

@misc{yang2020finbert,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {2006.08097},
    year = {2020},
    author = {Yi Yang and Mark Christopher Siy UY and Allen Huang},
    title = {{FinBERT:} {A} {Pretrained} {Language} {Model} for {Financial} {Communications}},
}

@misc{paul2023pretrained,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {2209.06049},
    year = {2023},
    author = {Shounak Paul and Arpan Mandal and Pawan Goyal and Saptarshi Ghosh},
    title = {{Pre-trained} {Language} {Models} for the {Legal} {Domain:} {A} {Case} {Study} on {Indian} {Law}},
}

@inproceedings{chalkidis-etal-2020-legal,
    abstract = {BERT has achieved impressive performance in several NLP tasks. However, there has been limited investigation on its adaptation guidelines in specialised domains. Here we focus on the legal domain, where we explore several approaches for applying BERT models to downstream legal tasks, evaluating on multiple datasets. Our findings indicate that the previous guidelines for pre-training and fine-tuning, often blindly followed, do not always generalize well in the legal domain. Thus we propose a systematic investigation of the available strategies when applying BERT in specialised domains. These are: (a) use the original BERT out of the box, (b) adapt BERT by additional pre-training on domain-specific corpora, and (c) pre-train BERT from scratch on domain-specific corpora. We also propose a broader hyper-parameter search space when fine-tuning for downstream tasks and we release LEGAL-BERT, a family of BERT models intended to assist legal NLP research, computational law, and legal technology applications.},
    pages = {2898--2904},
    doi = {10.18653/v1/2020.findings-emnlp.261},
    url = {https://aclanthology.org/2020.findings-emnlp.261},
    publisher = {Association for Computational Linguistics},
    address = {Online},
    year = {2020},
    month = {nov},
    booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2020},
    editor = {Cohn, Trevor  and
He, Yulan  and
Liu, Yang},
    author = {Chalkidis, Ilias  and
Fergadiotis, Manos  and
Malakasiotis, Prodromos  and
Aletras, Nikolaos  and
Androutsopoulos, Ion},
    title = {{LEGAL}-{BERT}: {The} {Muppets} {Straight} {Out} of {Law} {School}},
}

@mastersthesis{Shrestha2021,
    year = {2021},
    school = {Hochschule Rhein-Waal},
    pages = {141},
    type = {masterthesis},
    title = {{Development} of a {Language} {Model} for {Medical} {Domain}},
    author = {Manjil Shrestha},
}

@inproceedings{schneider-etal-2020-biobertpt,
    abstract = {With the growing number of electronic health record data, clinical NLP tasks have become increasingly relevant to unlock valuable information from unstructured clinical text. Although the performance of downstream NLP tasks, such as named-entity recognition (NER), in English corpus has recently improved by contextualised language models, less research is available for clinical texts in low resource languages. Our goal is to assess a deep contextual embedding model for Portuguese, so called BioBERTpt, to support clinical and biomedical NER. We transfer learned information encoded in a multilingual-BERT model to a corpora of clinical narratives and biomedical-scientific papers in Brazilian Portuguese. To evaluate the performance of BioBERTpt, we ran NER experiments on two annotated corpora containing clinical narratives and compared the results with existing BERT models. Our in-domain model outperformed the baseline model in F1-score by 2.72{\%}, achieving higher performance in 11 out of 13 assessed entities. We demonstrate that enriching contextual embedding models with domain literature can play an important role in improving performance for specific NLP tasks. The transfer learning process enhanced the Portuguese biomedical NER model by reducing the necessity of labeled data and the demand for retraining a whole new model.},
    pages = {65--72},
    doi = {10.18653/v1/2020.clinicalnlp-1.7},
    url = {https://aclanthology.org/2020.clinicalnlp-1.7},
    publisher = {Association for Computational Linguistics},
    address = {Online},
    year = {2020},
    month = {nov},
    booktitle = {Proceedings of the 3rd Clinical Natural Language Processing Workshop},
    editor = {Rumshisky, Anna  and
Roberts, Kirk  and
Bethard, Steven  and
Naumann, Tristan},
    author = {Schneider, Elisa Terumi Rubel  and
de Souza, Jo{\~a}o Vitor Andrioli  and
Knafou, Julien  and
Oliveira, Lucas Emanuel Silva e  and
Copara, Jenny  and
Gumiel, Yohan Bonescki  and
Oliveira, Lucas Ferro Antunes de  and
Paraiso, Emerson Cabrera  and
Teodoro, Douglas  and
Barra, Cl{\'a}udia Maria Cabral Moro},
    title = {{B}io{BERT}pt {-} {A} {P}ortuguese {Neural} {Language} {Model} for {Clinical} {Named} {Entity} {Recognition}},
}

@misc{carrino2021biomedical,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {2109.03570},
    year = {2021},
    author = {Casimiro Pio Carrino and Jordi Armengol-Estapé and Asier Gutiérrez-Fandiño and Joan Llop-Palao and Marc Pàmies and Aitor Gonzalez-Agirre and Marta Villegas},
    title = {{Biomedical} and {Clinical} {Language} {Models} for {Spanish:} {On} the {Benefits} of {Domain-Specific} {Pretraining} in a {Mid-Resource} {Scenario}},
}

@article{turkmen_bioberturk_2023,
    date = {2023-12-01},
    author = {Türkmen, Hazal and Dikenelli, Oğuz and Eraslan, Cenk and Çallı, Mehmet Cem and Özbek, Süha Süreyya},
    shortjournal = {Journal of Healthcare Informatics Research},
    journaltitle = {Journal of Healthcare Informatics Research},
    number = {4},
    pages = {433--446},
    abstract = {Pretrained language models augmented with in-domain corpora show impressive results in biomedicine and clinical Natural Language Processing ({NLP}) tasks in English. However, there has been minimal work in low-resource languages. Although some pioneering works have shown promising results, many scenarios still need to be explored to engineer effective pretrained language models in biomedicine for low-resource settings. This study introduces the {BioBERTurk} family and four pretrained models in Turkish for biomedicine. To evaluate the models, we also introduced a labeled dataset to classify radiology reports of head {CT} examinations. Two parts of the reports, impressions and findings, are evaluated separately to observe the performance of models on longer and less informative text. We compared the models with the Turkish {BERT} ({BERTurk}) pretrained with general domain text, multilingual {BERT} ({mBERT}), and {LSTM}+attention-based baseline models. The first model initialized from {BERTurk} and then further pretrained with biomedical corpus performs statistically better than {BERTurk}, multilingual {BERT}, and baseline for both datasets. The second model continues to pretrain the {BERTurk} model by using only radiology Ph.D. theses to test the effect of task-related text. This model slightly outperformed all models on the impression dataset and showed that using only radiology-related data for continual pre-training could be effective. The third model continues to pretrain by adding radiology theses to the biomedical corpus but does not show a statistically meaningful difference for both datasets. The final model combines radiology and biomedicine corpora with the corpus of {BERTurk} and pretrains a {BERT} model from scratch. This model is the worst-performing model of the {BioBERT} family, even worse than {BERTurk} and multilingual {BERT}.},
    doi = {10.1007/s41666-023-00140-7},
    year = {2023},
    url = {https://doi.org/10.1007/s41666-023-00140-7},
    issn = {2509-498X},
    volume = {7},
    title = {{BioBERTurk}: {Exploring} {Turkish} {Biomedical} {Language} {Model} {Development} {Strategies} in {Low-Resource} {Setting}},
}

@inproceedings{labrak2023drbert,
    publisher = {Association for Computational Linguistics},
    address = {Toronto, Canada},
    year = {2023},
    month = {jul},
    booktitle = {Proceedings of the 61th Annual Meeting of the Association for Computational Linguistics (ACL'23), Long Paper},
    author = {Labrak, Yanis and Bazoge, Adrien and Dufour, Richard and Rouvier, Mickael and Morin, Emmanuel and Daille, Béatrice and Gourraud, Pierre-Antoine},
    title = {{DrBERT:} {A} {Robust} {Pre-trained} {Model} in {French} for {Biomedical} and {Clinical} {Domains}},
}

@misc{sanh2020distilbert,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {1910.01108},
    year = {2020},
    author = {Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
    title = {{DistilBERT,} a {Distilled} {Version} of {BERT:} {Smaller,} {Faster,} {Cheaper} and {Lighter}},
}

@article{DBLP:journals/corr/ChoMGBSB14,
    bibsource = {dblp computer science bibliography, https://dblp.org},
    biburl = {https://dblp.org/rec/journals/corr/ChoMGBSB14.bib},
    timestamp = {Mon, 13 Aug 2018 16:46:44 +0200},
    eprint = {1406.1078},
    eprinttype = {arXiv},
    url = {http://arxiv.org/abs/1406.1078},
    year = {2014},
    volume = {abs/1406.1078},
    journal = {CoRR},
    title = {{Learning} {Phrase} {Representations} {Using} {RNN} {Encoder-Decoder} for {Statistical} {Machine} {Translation}},
    author = {Kyunghyun Cho and
Bart van Merrienboer and
{\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
Fethi Bougares and
Holger Schwenk and
Yoshua Bengio},
}

@article{4051119,
    doi = {10.1109/JRPROC.1952.273898},
    keywords = {Transmitters},
    pages = {1098-1101},
    number = {9},
    volume = {40},
    year = {1952},
    title = {{A} {Method} for the {Construction} of {Minimum-Redundancy} {Codes}},
    journal = {Proceedings of the IRE},
    author = {Huffman, David A.},
}

@article{DBLP:journals/corr/abs-2010-11929,
    bibsource = {dblp computer science bibliography, https://dblp.org},
    biburl = {https://dblp.org/rec/journals/corr/abs-2010-11929.bib},
    timestamp = {Fri, 20 Nov 2020 14:04:05 +0100},
    eprint = {2010.11929},
    eprinttype = {arXiv},
    url = {https://arxiv.org/abs/2010.11929},
    year = {2020},
    volume = {abs/2010.11929},
    journal = {CoRR},
    title = {{An} {Image} is {Worth} {16x16} {Words:} {Transformers} for {Image} {Recognition} at {Scale}},
    author = {Alexey Dosovitskiy and
Lucas Beyer and
Alexander Kolesnikov and
Dirk Weissenborn and
Xiaohua Zhai and
Thomas Unterthiner and
Mostafa Dehghani and
Matthias Minderer and
Georg Heigold and
Sylvain Gelly and
Jakob Uszkoreit and
Neil Houlsby},
}

@misc{radford2022robust,
    primaryclass = {eess.AS},
    archiveprefix = {arXiv},
    eprint = {2212.04356},
    year = {2022},
    author = {Alec Radford and Jong Wook Kim and Tao Xu and Greg Brockman and Christine McLeavey and Ilya Sutskever},
    title = {{Robust} {Speech} {Recognition} via {Large-Scale} {Weak} {Supervision}},
}

@misc{schwenk2020ccmatrix,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {1911.04944},
    year = {2020},
    author = {Holger Schwenk and Guillaume Wenzek and Sergey Edunov and Edouard Grave and Armand Joulin},
    title = {{CCMatrix:} {Mining} {Billions} of {High-Quality} {Parallel} {Sentences} on the {WEB}},
}

@inproceedings{el-kishky-etal-2020-ccaligned,
    abstract = {Cross-lingual document alignment aims to identify pairs of documents in two distinct languages that are of comparable content or translations of each other. In this paper, we exploit the signals embedded in URLs to label web documents at scale with an average Precision of 94.5{\%} across different language pairs. We mine sixty-eight snapshots of the Common Crawl corpus and identify web document pairs that are translations of each other. We release a new web dataset consisting of over 392 million URL pairs from Common Crawl covering documents in 8144 language pairs of which 137 pairs include English. In addition to curating this massive dataset, we introduce baseline methods that leverage cross-lingual representations to identify aligned documents based on their textual content. Finally, we demonstrate the value of this parallel documents dataset through a downstream task of mining parallel sentences and measuring the quality of machine translations from models trained on this mined data. Our objective in releasing this dataset is to foster new research in cross-lingual NLP across a variety of low, medium, and high-resource languages.},
    pages = {5960--5969},
    doi = {10.18653/v1/2020.emnlp-main.480},
    url = {https://aclanthology.org/2020.emnlp-main.480},
    publisher = {Association for Computational Linguistics},
    address = {Online},
    year = {2020},
    month = {nov},
    booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
    editor = {Webber, Bonnie  and
Cohn, Trevor  and
He, Yulan  and
Liu, Yang},
    author = {El-Kishky, Ahmed  and
Chaudhary, Vishrav  and
Guzm{\'a}n, Francisco  and
Koehn, Philipp},
    title = {{CCA}ligned: {A} {Massive} {Collection} of {Cross-Lingual} {Web-Document} {Pairs}},
}

@article{Artetxe_2019,
    pages = {597–610},
    month = {nov},
    year = {2019},
    author = {Artetxe, Mikel and Schwenk, Holger},
    publisher = {MIT Press - Journals},
    journal = {Transactions of the Association for Computational Linguistics},
    doi = {10.1162/tacl_a_00288},
    url = {http://dx.doi.org/10.1162/tacl_a_00288},
    issn = {2307-387X},
    volume = {7},
    title = {{Massively} {Multilingual} {Sentence} {Embeddings} for {Zero-Shot} {Cross-Lingual} {Transfer} and {Beyond}},
}

@article{jensson_language_2009,
    date = {2009-01-27},
    author = {Jensson, {ArnarThor} and Iwano, Koji and Furui, Sadaoki},
    shortjournal = {{EURASIP} Journal on Audio, Speech, and Music Processing},
    journaltitle = {{EURASIP} Journal on Audio, Speech, and Music Processing},
    number = {1},
    pages = {573832},
    abstract = {Text corpus size is an important issue when building a language model ({LM}). This is a particularly important issue for languages where little data is available. This paper introduces an {LM} adaptation technique to improve an {LM} built using a small amount of task-dependent text with the help of a machine-translated text corpus. Icelandic speech recognition experiments were performed using data, machine translated ({MT}) from English to Icelandic on a word-by-word and sentence-by-sentence basis. {LM} interpolation using the baseline {LM} and an {LM} built from either word-by-word or sentence-by-sentence translated text reduced the word error rate significantly when manually obtained utterances used as a baseline were very sparse.},
    doi = {10.1155/2008/573832},
    url = {https://doi.org/10.1155/2008/573832},
    issn = {1687-4722},
    volume = {2008},
    title = {{Language} {Model} {Adaptation} {Using} {Machine-Translated} {Text} for {Resource-Deficient} {Languages}},
}

@inproceedings{caswell-etal-2019-tagged,
    abstract = {Recent work in Neural Machine Translation (NMT) has shown significant quality gains from noised-beam decoding during back-translation, a method to generate synthetic parallel data. We show that the main role of such synthetic noise is not to diversify the source side, as previously suggested, but simply to indicate to the model that the given source is synthetic. We propose a simpler alternative to noising techniques, consisting of tagging back-translated source sentences with an extra token. Our results on WMT outperform noised back-translation in English-Romanian and match performance on English-German, redefining the state-of-the-art on the former.},
    pages = {53--63},
    doi = {10.18653/v1/W19-5206},
    url = {https://aclanthology.org/W19-5206},
    publisher = {Association for Computational Linguistics},
    address = {Florence, Italy},
    year = {2019},
    month = {aug},
    booktitle = {Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers)},
    editor = {Bojar, Ond{\v{r}}ej  and
Chatterjee, Rajen  and
Federmann, Christian  and
Fishel, Mark  and
Graham, Yvette  and
Haddow, Barry  and
Huck, Matthias  and
Yepes, Antonio Jimeno  and
Koehn, Philipp  and
Martins, Andr{\'e}  and
Monz, Christof  and
Negri, Matteo  and
N{\'e}v{\'e}ol, Aur{\'e}lie  and
Neves, Mariana  and
Post, Matt  and
Turchi, Marco  and
Verspoor, Karin},
    author = {Caswell, Isaac  and
Chelba, Ciprian  and
Grangier, David},
    title = {{Tagged} {Back-Translation}},
}

@article{10.3389/fdgth.2023.1195017,
    abstract = {<sec><title>Objectives</title><p>The objective of this study is the exploration of Artificial Intelligence and Natural Language Processing techniques to support the automatic assignment of the four Response Evaluation Criteria in Solid Tumors (RECIST) scales based on radiology reports. We also aim at evaluating how languages and institutional specificities of Swiss teaching hospitals are likely to affect the quality of the classification in French and German languages.</p></sec><sec><title>Methods</title><p>In our approach, 7 machine learning methods were evaluated to establish a strong baseline. Then, robust models were built, fine-tuned according to the language (French and German), and compared with the expert annotation.</p></sec><sec><title>Results</title><p>The best strategies yield average F1-scores of 90% and 86% respectively for the 2-classes (Progressive/Non-progressive) and the 4-classes (Progressive Disease, Stable Disease, Partial Response, Complete Response) RECIST classification tasks.</p></sec><sec><title>Conclusions</title><p>These results are competitive with the manual labeling as measured by Matthew's correlation coefficient and Cohen's Kappa (79% and 76%). On this basis, we confirm the capacity of specific models to generalize on new unseen data and we assess the impact of using Pre-trained Language Models (PLMs) on the accuracy of the classifiers.</p></sec>},
    issn = {2673-253X},
    doi = {10.3389/fdgth.2023.1195017},
    url = {https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2023.1195017},
    year = {2023},
    volume = {5},
    journal = {Frontiers in Digital Health},
    title = {{Multilingual} {RECIST} {Classification} of {Radiology} {Reports} {Using} {Supervised} {Learning}},
    author = {Mottin, Luc  and Goldman, Jean-Philippe  and Jäggli, Christoph  and Achermann, Rita  and Gobeill, Julien  and Knafou, Julien  and Ehrsam, Julien  and Wicky, Alexandre  and Gérard, Camille L.  and Schwenk, Tanja  and Charrier, Mélinda  and Tsantoulis, Petros  and Lovis, Christian  and Leichtle, Alexander  and Kiessling, Michael K.  and Michielin, Olivier  and Pradervand, Sylvain  and Foufi, Vasiliki  and Ruch, Patrick},
}

@inproceedings{knafou-etal-2020-bitem,
    abstract = {Recent improvements in machine-reading technologies attracted much attention to automation problems and their possibilities. In this context, WNUT 2020 introduces a Name Entity Recognition (NER) task based on wet laboratory procedures. In this paper, we present a 3-step method based on deep neural language models that reported the best overall exact match F1-score (77.99{\%}) of the competition. By fine-tuning 10 times, 10 different pretrained language models, this work shows the advantage of having more models in an ensemble based on a majority of votes strategy. On top of that, having 100 different models allowed us to analyse the combinations of ensemble that demonstrated the impact of having multiple pretrained models versus fine-tuning a pretrained model multiple times.},
    pages = {305--313},
    doi = {10.18653/v1/2020.wnut-1.40},
    url = {https://aclanthology.org/2020.wnut-1.40},
    publisher = {Association for Computational Linguistics},
    address = {Online},
    year = {2020},
    month = {nov},
    booktitle = {Proceedings of the Sixth Workshop on Noisy User-generated Text (W-NUT 2020)},
    editor = {Xu, Wei  and
Ritter, Alan  and
Baldwin, Tim  and
Rahimi, Afshin},
    author = {Knafou, Julien  and
Naderi, Nona  and
Copara, Jenny  and
Teodoro, Douglas  and
Ruch, Patrick},
    title = {{B}i{T}e{M} at {WNUT} {2020} {Shared} {Task-1:} {Named} {Entity} {Recognition} {Over} {Wet} {Lab} {Protocols} {Using} an {Ensemble} of {Contextual} {Language} {Models}},
}

@misc{copara2020named,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {2007.12569},
    year = {2020},
    author = {Jenny Copara and Nona Naderi and Julien Knafou and Patrick Ruch and Douglas Teodoro},
    title = {{Named} {Entity} {Recognition} in {Chemical} {Patents} {Using} {Ensemble} of {Contextual} {Language} {Models}},
}

@inproceedings{tabassum-etal-2020-wnut,
    abstract = {This paper presents the results of the wet labinformation extraction task at WNUT 2020.This task consisted of two sub tasks- (1) anamed entity recognition task with 13 partic-ipants; and (2) a relation extraction task with2 participants. We outline the task, data an-notation process, corpus statistics, and providea high-level overview of the participating sys-tems for each sub task.},
    pages = {260--267},
    doi = {10.18653/v1/2020.wnut-1.33},
    url = {https://aclanthology.org/2020.wnut-1.33},
    publisher = {Association for Computational Linguistics},
    address = {Online},
    year = {2020},
    month = {nov},
    booktitle = {Proceedings of the Sixth Workshop on Noisy User-generated Text (W-NUT 2020)},
    editor = {Xu, Wei  and
Ritter, Alan  and
Baldwin, Tim  and
Rahimi, Afshin},
    author = {Tabassum, Jeniya  and
Xu, Wei  and
Ritter, Alan},
    title = {{WNUT}-2020 {Task} {1} {Overview:} {Extracting} {Entities} and {Relations} {From} {Wet} {Lab} {Protocols}},
}

@misc{nentidis2023overview,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {2307.05131},
    year = {2023},
    author = {Anastasios Nentidis and Georgios Katsimpras and Anastasia Krithara and Salvador Lima López and Eulália Farré-Maduell and Luis Gasco and Martin Krallinger and Georgios Paliouras},
    title = {{Overview} of {BioASQ} {2023:} {The} {Eleventh} {BioASQ} {Challenge} on {Large-Scale} {Biomedical} {Semantic} {Indexing} and {Question} {Answering}},
}

@inproceedings{Almeida2023BITUAAB,
    url = {https://api.semanticscholar.org/CorpusID:264441682},
    year = {2023},
    booktitle = {Conference and Labs of the Evaluation Forum},
    author = {Tiago Almeida and Richard Adolph Aires Jonker and Roshan Poudel and Jorge M. Silva and S{\'e}rgio Matos},
    title = {{BIT.UA} at {BioASQ} {11B:} {Two-Stage} {IR} with {Synthetic} {Training} and {Zero-Shot} {Answer} {Generation}},
}

@misc{voorhees2020treccovid,
    primaryclass = {cs.IR},
    archiveprefix = {arXiv},
    eprint = {2005.04474},
    year = {2020},
    author = {Ellen Voorhees and Tasmeer Alam and Steven Bedrick and Dina Demner-Fushman and William R Hersh and Kyle Lo and Kirk Roberts and Ian Soboroff and Lucy Lu Wang},
    title = {{TREC-COVID:} {Constructing} a {Pandemic} {Information} {Retrieval} {Test} {Collection}},
}

@inproceedings{10.1145/3077136.3080721,
    series = {SIGIR '17},
    location = {Shinjuku, Tokyo, Japan},
    keywords = {multi-threaded inverted indexing, open-source toolkits, reproducibility, trec test collections},
    numpages = {4},
    pages = {1253–1256},
    booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
    abstract = {Software toolkits play an essential role in information retrieval research. Most open-source toolkits developed by academics are designed to facilitate the evaluation of retrieval models over standard test collections. Efforts are generally directed toward better ranking and less attention is usually given to scalability and other operational considerations. On the other hand, Lucene has become the de facto platform in industry for building search applications (outside a small number of companies that deploy custom infrastructure). Compared to academic IR toolkits, Lucene can handle heterogeneous web collections at scale, but lacks systematic support for evaluation over standard test collections. This paper introduces Anserini, a new information retrieval toolkit that aims to provide the best of both worlds, to better align information retrieval practice and research. Anserini provides wrappers and extensions on top of core Lucene libraries that allow researchers to use more intuitive APIs to accomplish common research tasks. Our initial efforts have focused on three functionalities: scalable, multi-threaded inverted indexing to handle modern web-scale collections, streamlined IR evaluation for ad hoc retrieval on standard test collections, and an extensible architecture for multi-stage ranking. Anserini ships with support for many TREC test collections, providing a convenient way to replicate competitive baselines right out of the box. Experiments verify that our system is both efficient and effective, providing a solid foundation to support future research.},
    doi = {10.1145/3077136.3080721},
    url = {https://doi.org/10.1145/3077136.3080721},
    address = {New York, NY, USA},
    publisher = {Association for Computing Machinery},
    isbn = {9781450350228},
    year = {2017},
    title = {{Anserini:} {Enabling} the {Use} of {Lucene} for {Information} {Retrieval} {Research}},
    author = {Yang, Peilin and Fang, Hui and Lin, Jimmy},
}

@misc{touvron2023llama,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {2302.13971},
    year = {2023},
    author = {Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
    title = {{LLaMA:} {Open} and {Efficient} {Foundation} {Language} {Models}},
}

@misc{roberts2021searching,
    primaryclass = {cs.IR},
    archiveprefix = {arXiv},
    eprint = {2104.09632},
    year = {2021},
    author = {Kirk Roberts and Tasmeer Alam and Steven Bedrick and Dina Demner-Fushman and Kyle Lo and Ian Soboroff and Ellen Voorhees and Lucy Lu Wang and William R Hersh},
    title = {{Searching} for {Scientific} {Evidence} in a {Pandemic:} {An} {Overview} of {TREC-COVID}},
}

@article{info:doi/10.2196/30161,
    url = {https://www.jmir.org/2021/9/e30161},
    doi = {10.2196/30161},
    issn = {1438-8871},
    abstract = {Background: The COVID-19 global health crisis has led to an exponential surge in published scientific literature. In an attempt to tackle the pandemic, extremely large COVID-19--related corpora are being created, sometimes with inaccurate information, which is no longer at scale of human analyses. Objective: In the context of searching for scientific evidence in the deluge of COVID-19--related literature, we present an information retrieval methodology for effective identification of relevant sources to answer biomedical queries posed using natural language. Methods: Our multistage retrieval methodology combines probabilistic weighting models and reranking algorithms based on deep neural architectures to boost the ranking of relevant documents. Similarity of COVID-19 queries is compared to documents, and a series of postprocessing methods is applied to the initial ranking list to improve the match between the query and the biomedical information source and boost the position of relevant documents. Results: The methodology was evaluated in the context of the TREC-COVID challenge, achieving competitive results with the top-ranking teams participating in the competition. Particularly, the combination of bag-of-words and deep neural language models significantly outperformed an Okapi Best Match 25--based baseline, retrieving on average, 83{\%} of relevant documents in the top 20. Conclusions: These results indicate that multistage retrieval supported by deep learning could enhance identification of literature for COVID-19--related questions posed using natural language.},
    keywords = {information retrieval; multistage retrieval; neural search; deep learning; COVID-19; coronavirus; infodemic; infodemiology; literature; online information},
    pages = {e30161},
    number = {9},
    volume = {23},
    day = {17},
    month = {Sep},
    year = {2021},
    journal = {J Med Internet Res},
    title = {{Information} {Retrieval} in an {Infodemic:} {The} {Case} of {COVID-19} {Publications}},
    author = {Teodoro, Douglas
and Ferdowsi, Sohrab
and Borissov, Nikolay
and Kashani, Elham
and Vicente Alvarez, David
and Copara, Jenny
and Gouareb, Racha
and Naderi, Nona
and Amini, Poorya},
}

@inproceedings{lothritz-etal-2022-luxembert,
    abstract = {Pre-trained Language Models such as BERT have become ubiquitous in NLP where they have achieved state-of-the-art performance in most NLP tasks. While these models are readily available for English and other widely spoken languages, they remain scarce for low-resource languages such as Luxembourgish. In this paper, we present LuxemBERT, a BERT model for the Luxembourgish language that we create using the following approach: we augment the pre-training dataset by considering text data from a closely related language that we partially translate using a simple and straightforward method. We are then able to produce the LuxemBERT model, which we show to be effective for various NLP tasks: it outperforms a simple baseline built with the available Luxembourgish text data as well the multilingual mBERT model, which is currently the only option for transformer-based language models in Luxembourgish. Furthermore, we present datasets for various downstream NLP tasks that we created for this study and will make available to researchers on request.},
    pages = {5080--5089},
    url = {https://aclanthology.org/2022.lrec-1.543},
    publisher = {European Language Resources Association},
    address = {Marseille, France},
    year = {2022},
    month = {jun},
    booktitle = {Proceedings of the Thirteenth Language Resources and Evaluation Conference},
    editor = {Calzolari, Nicoletta  and
B{\'e}chet, Fr{\'e}d{\'e}ric  and
Blache, Philippe  and
Choukri, Khalid  and
Cieri, Christopher  and
Declerck, Thierry  and
Goggi, Sara  and
Isahara, Hitoshi  and
Maegaard, Bente  and
Mariani, Joseph  and
Mazo, H{\'e}l{\`e}ne  and
Odijk, Jan  and
Piperidis, Stelios},
    author = {Lothritz, Cedric  and
Lebichot, Bertrand  and
Allix, Kevin  and
Veiber, Lisa  and
Bissyande, Tegawende  and
Klein, Jacques  and
Boytsov, Andrey  and
Lefebvre, Cl{\'e}ment  and
Goujon, Anne},
    title = {{L}uxem{BERT}: {Simple} and {Practical} {Data} {Augmentation} in {Language} {Model} {Pre-Training} for {L}uxembourgish},
}

@inproceedings{phan-etal-2023-enriching,
    abstract = {Biomedical data and benchmarks are highly valuable yet very limited in low-resource languages other than English, such as Vietnamese. In this paper, we use a state-of-the-art translation model in English-Vietnamese to translate and produce both pretrained and supervised data in the biomedical domains. Thanks to such large-scale translation, we introduce ViPubmedT5, a pretrained Encoder-Decoder Transformer model trained on 20 million translated abstracts from the high-quality public PubMed corpus. ViPubMedT5 demonstrates state-of-the-art results on two different biomedical benchmarks in summarization and acronym disambiguation. Further, we release ViMedNLI - a new NLP task in Vietnamese translated from MedNLI using the recently public En-vi translation model and carefully refined by human experts, with evaluations of existing methods against ViPubmedT5.},
    pages = {3131--3142},
    doi = {10.18653/v1/2023.eacl-main.228},
    url = {https://aclanthology.org/2023.eacl-main.228},
    publisher = {Association for Computational Linguistics},
    address = {Dubrovnik, Croatia},
    year = {2023},
    month = {may},
    booktitle = {Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
    editor = {Vlachos, Andreas  and
Augenstein, Isabelle},
    author = {Phan, Long  and
Dang, Tai  and
Tran, Hieu  and
Trinh, Trieu H.  and
Phan, Vy  and
Chau, Lam D.  and
Luong, Minh-Thang},
    title = {{Enriching} {Biomedical} {Knowledge} for {Low-resource} {Language} {Through} {Large-scale} {Translation}},
}

@inproceedings{urbizu-etal-2023-enough,
    abstract = {In recent years, pre-trained transformer-based language models (LM) have become a key resource for implementing most NLP tasks. However, pre-training such models demands large text collections not available in most languages. In this paper, we study the use of machine-translated corpora for pre-training LMs. We answer the following research questions: RQ1: Is MT-based data an alternative to real data for learning a LM?; RQ2: Can real data be complemented with translated data and improve the resulting LM? In order to validate these two questions, several BERT models for Basque have been trained, combining real data and synthetic data translated from Spanish.The evaluation carried out on 9 NLU tasks indicates that models trained exclusively on translated data offer competitive results. Furthermore, models trained with real data can be improved with synthetic data, although further research is needed on the matter.},
    pages = {3826--3836},
    doi = {10.18653/v1/2023.findings-acl.235},
    url = {https://aclanthology.org/2023.findings-acl.235},
    publisher = {Association for Computational Linguistics},
    address = {Toronto, Canada},
    year = {2023},
    month = {jul},
    booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
    editor = {Rogers, Anna  and
Boyd-Graber, Jordan  and
Okazaki, Naoaki},
    author = {Urbizu, Gorka  and
San Vicente, I{\~n}aki  and
Saralegi, Xabier  and
Corral, Ander},
    title = {{Not} {Enough} {Data} to {Pre-train} {Your} {Language} {Model?} {MT} to the {Rescue!}},
}

@inproceedings{urbizu-etal-2022-basqueglue,
    abstract = {Natural Language Understanding (NLU) technology has improved significantly over the last few years and multitask benchmarks such as GLUE are key to evaluate this improvement in a robust and general way. These benchmarks take into account a wide and diverse set of NLU tasks that require some form of language understanding, beyond the detection of superficial, textual clues. However, they are costly to develop and language-dependent, and therefore they are only available for a small number of languages. In this paper, we present BasqueGLUE, the first NLU benchmark for Basque, a less-resourced language, which has been elaborated from previously existing datasets and following similar criteria to those used for the construction of GLUE and SuperGLUE. We also report the evaluation of two state-of-the-art language models for Basque on BasqueGLUE, thus providing a strong baseline to compare upon. BasqueGLUE is freely available under an open license.},
    pages = {1603--1612},
    url = {https://aclanthology.org/2022.lrec-1.172},
    publisher = {European Language Resources Association},
    address = {Marseille, France},
    year = {2022},
    month = {jun},
    booktitle = {Proceedings of the Thirteenth Language Resources and Evaluation Conference},
    editor = {Calzolari, Nicoletta  and
B{\'e}chet, Fr{\'e}d{\'e}ric  and
Blache, Philippe  and
Choukri, Khalid  and
Cieri, Christopher  and
Declerck, Thierry  and
Goggi, Sara  and
Isahara, Hitoshi  and
Maegaard, Bente  and
Mariani, Joseph  and
Mazo, H{\'e}l{\`e}ne  and
Odijk, Jan  and
Piperidis, Stelios},
    author = {Urbizu, Gorka  and
San Vicente, I{\~n}aki  and
Saralegi, Xabier  and
Agerri, Rodrigo  and
Soroa, Aitor},
    title = {{B}asque{GLUE}: {A} {Natural} {Language} {Understanding} {Benchmark} for {B}asque},
}

@misc{romanov2018lessons,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {1808.06752},
    year = {2018},
    author = {Alexey Romanov and Chaitanya Shivade},
    title = {{Lessons} {From} {Natural} {Language} {Inference} in the {Clinical} {Domain}},
}

@misc{ngo2022mtet,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {2210.05610},
    year = {2022},
    author = {Chinh Ngo and Trieu H. Trinh and Long Phan and Hieu Tran and Tai Dang and Hieu Nguyen and Minh Nguyen and Minh-Thang Luong},
    title = {{MTet:} {Multi-domain} {Translation} for {English} and {Vietnamese}},
}

@misc{phan2022vit5,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {2205.06457},
    year = {2022},
    author = {Long Phan and Hieu Tran and Hieu Nguyen and Trieu H. Trinh},
    title = {{ViT5:} {Pretrained} {Text-to-Text} {Transformer} for {Vietnamese} {Language} {Generation}},
}

@misc{raffel2023exploring,
    primaryclass = {cs.LG},
    archiveprefix = {arXiv},
    eprint = {1910.10683},
    year = {2023},
    author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
    title = {{Exploring} the {Limits} of {Transfer} {Learning} with a {Unified} {Text-to-Text} {Transformer}},
}

@misc{brown2020language,
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {2005.14165},
    year = {2020},
    author = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
    title = {{Language} {Models} {Are} {Few-Shot} {Learners}},
}

@article{PMID:44,
    url = {https://doi.org/10.1021/bi00695a003},
    abstract = {Above pH 8.5, pepsinogen is converted into a form which cannot be activated to pepsin on exposure to low pH. Intermediate exposure to neutral pH, however, returns the protein to a form which can be activated. Evidence is presented for a reversible, small conformational change in the molecule, distinct from the unfolding of the protein. At the same time, the molecule is converted to a form of limited solubility, which is precipitated at low pH, where activation is normally seen. The results are interpreted in terms of the peculiar structure of the pepsinogen molecule. Titration of the basic NH2-terminal region produced an open form, which can return to the native form at neutral pH, but which is maintained at low pH by neutralization of carboxylate groups in the pepsin portion.},
    pages = {5253—5256},
    issn = {0006-2960},
    journal = {Biochemistry},
    year = {1975},
    month = {December},
    volume = {14},
    number = {24},
    doi = {10.1021/bi00695a003},
    author = {McPhie, P},
    title = {{The} {Origin} of the {Alkaline} {Inactivation} of {Pepsinogen}},
}

@book{nltk,
    publisher = {O'Reilly Media, Inc.},
    year = {2009},
    author = {Bird, Steven and Klein, Ewan and Loper, Edward},
    title = {{Natural} {Language} {Processing} with {Python:} {Analyzing} {Text} with the {Natural} {Language} {Toolkit}},
}

@inproceedings{labrak:hal-04470938,
    hal_version = {v1},
    hal_id = {hal-04470938},
    pdf = {https://hal.science/hal-04470938/file/DrBenchmark.pdf},
    keywords = {NLP evaluation ; Benchmarking ; Medical domain ; French language ; Transformers},
    month = {may},
    year = {2024},
    organization = {Nicoletta Calzolari and Min-Yen Kan},
    address = {Torino, Italy},
    booktitle = {Fourteenth Language Resources and Evaluation Conference (LREC-COLING 2024)},
    url = {https://hal.science/hal-04470938},
    author = {Labrak, Yanis and Bazoge, Adrien and El Khettari, Oumaima and Rouvier, Micka{\"e}l and Constant Dit Beaufils, Pac{\^o}me and Grabar, Natalia and Daille, B{\'e}atrice and Quiniou, Solen and Morin, Emmanuel and Gourraud, Pierre-antoine and Dufour, Richard},
    title = {{DrBenchmark:} {A} {Large} {Language} {Understanding} {Evaluation} {Benchmark} for {French} {Biomedical} {Domain}},
}

@inproceedings{grabar-etal-2018-cas,
    abstract = {Textual corpora are extremely important for various NLP applications as they provide information necessary for creating, setting and testing these applications and the corresponding tools. They are also crucial for designing reliable methods and reproducible results. Yet, in some areas, such as the medical area, due to confidentiality or to ethical reasons, it is complicated and even impossible to access textual data representative of those produced in these areas. We propose the CAS corpus built with clinical cases, such as they are reported in the published scientific literature in French. We describe this corpus, currently containing over 397,000 word occurrences, and the existing linguistic and semantic annotations.},
    pages = {122--128},
    doi = {10.18653/v1/W18-5614},
    url = {https://aclanthology.org/W18-5614},
    publisher = {Association for Computational Linguistics},
    address = {Brussels, Belgium},
    year = {2018},
    month = {oct},
    booktitle = {Proceedings of the Ninth International Workshop on Health Text Mining and Information Analysis},
    editor = {Lavelli, Alberto  and
Minard, Anne-Lyse  and
Rinaldi, Fabio},
    author = {Grabar, Natalia  and
Claveau, Vincent  and
Dalloux, Cl{\'e}ment},
    title = {{CAS}: {F}rench {Corpus} with {Clinical} {Cases}},
}

@inproceedings{hiebel-etal-2022-clister-corpus,
    abstract = {Modern Natural Language Processing relies on the availability of annotated corpora for training and evaluating models. Such resources are scarce, especially for specialized domains in languages other than English. In particular, there are very few resources for semantic similarity in the clinical domain in French. This can be useful for many biomedical natural language processing applications, including text generation. We introduce a definition of similarity that is guided by clinical facts and apply it to the development of a new French corpus of 1,000 sentence pairs manually annotated according to similarity scores. This new sentence similarity corpus is made freely available to the community. We further evaluate the corpus through experiments of automatic similarity measurement. We show that a model of sentence embeddings can capture similarity with state-of-the-art performance on the DEFT STS shared task evaluation data set (Spearman=0.8343). We also show that the corpus is complementary to DEFT STS.},
    pages = {4306--4315},
    url = {https://aclanthology.org/2022.lrec-1.459},
    publisher = {European Language Resources Association},
    address = {Marseille, France},
    year = {2022},
    month = {jun},
    booktitle = {Proceedings of the Thirteenth Language Resources and Evaluation Conference},
    editor = {Calzolari, Nicoletta  and
B{\'e}chet, Fr{\'e}d{\'e}ric  and
Blache, Philippe  and
Choukri, Khalid  and
Cieri, Christopher  and
Declerck, Thierry  and
Goggi, Sara  and
Isahara, Hitoshi  and
Maegaard, Bente  and
Mariani, Joseph  and
Mazo, H{\'e}l{\`e}ne  and
Odijk, Jan  and
Piperidis, Stelios},
    author = {Hiebel, Nicolas  and
Ferret, Olivier  and
Fort, Kar{\"e}n  and
N{\'e}v{\'e}ol, Aur{\'e}lie},
    title = {{CLISTER} {:} {A} {Corpus} for {Semantic} {Textual} {Similarity} in {F}rench {Clinical} {Narratives}},
}

@inbook{e3c,
    doi = {10.4000/books.aaccademia.8663},
    isbn = {9791280136336},
    title = {{The} {E3C} {Project:} {Collection} and {Annotation} of a {Multilingual} {Corpus} of {Clinical} {Cases}},
    pages = {258-264},
    month = {01},
    year = {2020},
    author = {Magnini, Bernardo and Altuna, Begoña and Lavelli, Alberto and Speranza, Manuela and Zanoli, Roberto},
}

@article{essai,
    pages = {181–201},
    year = {2021},
    author = {Dalloux, Clément and Claveau, Vincent and Grabar, Natalia and Oliveira, Lucas Emanuel Silva and Moro, Claudia Maria Cabral and Gumiel, Yohan Bonescki and Carvalho, Deborah Ribeiro},
    journal = {Natural Language Engineering},
    number = {2},
    doi = {10.1017/S1351324920000352},
    volume = {27},
    title = {{Supervised} {Learning} for the {Detection} of {Negation} and of {Its} {Scope} in {French} and {Brazilian} {Portuguese} {Biomedical} {Corpora}},
}

@inproceedings{labrak-etal-2022-frenchmedmcqa,
    abstract = {This paper introduces FrenchMedMCQA, the first publicly available Multiple-Choice Question Answering (MCQA) dataset in French for medical domain. It is composed of 3,105 questions taken from real exams of the French medical specialization diploma in pharmacy, mixing single and multiple answers. Each instance of the dataset contains an identifier, a question, five possible answers and their manual correction(s). We also propose first baseline models to automatically process this MCQA task in order to report on the current performances and to highlight the difficulty of the task. A detailed analysis of the results showed that it is necessary to have representations adapted to the medical domain or to the MCQA task: in our case, English specialized models yielded better results than generic French ones, even though FrenchMedMCQA is in French. Corpus, models and tools are available online.},
    pages = {41--46},
    doi = {10.18653/v1/2022.louhi-1.5},
    url = {https://aclanthology.org/2022.louhi-1.5},
    publisher = {Association for Computational Linguistics},
    address = {Abu Dhabi, United Arab Emirates (Hybrid)},
    year = {2022},
    month = {dec},
    booktitle = {Proceedings of the 13th International Workshop on Health Text Mining and Information Analysis (LOUHI)},
    editor = {Lavelli, Alberto  and
Holderness, Eben  and
Jimeno Yepes, Antonio  and
Minard, Anne-Lyse  and
Pustejovsky, James  and
Rinaldi, Fabio},
    author = {Labrak, Yanis  and
Bazoge, Adrien  and
Dufour, Richard  and
Daille, Beatrice  and
Gourraud, Pierre-Antoine  and
Morin, Emmanuel  and
Rouvier, Mickael},
    title = {{F}rench{M}ed{MCQA}: {A} {F}rench {Multiple-Choice} {Question} {Answering} {Dataset} for {Medical} {Domain}},
}

@book{icd-10,
    type = {Publications},
    publisher = {World Health Organization},
    edition = {10th revision, Fifth edition, 2016},
    pages = {3 volumes},
    year = {2015},
    title = {{International} {Statistical} {Classification} of {Diseases} and {Related} {Health} {Problems}},
    author = {World Health Organization},
}

@inproceedings{Labrak2023TchesES,
    url = {https://api.semanticscholar.org/CorpusID:264038842},
    year = {2023},
    booktitle = {JEPTALNRECITAL},
    author = {Yanis Labrak and Adrien Bazoge and B{\'e}atrice Daille and Richard Dufour and Emmanuel Morin and Mickael Rouvier},
    title = {T{\^a}ches {Et} syst{\`e}mes {De} d{\'e}tection {Automatique} {Des} r{\'e}ponses {Correctes} {Dans} {Des} {QCMs} li{\'e}s {Au} {Domaine} m{\'e}dical {:} Pr{\'e}sentation {De} {La} {Campagne} {DEFT} {2023}},
}

@misc{openai2024gpt4technicalreport,
    url = {https://arxiv.org/abs/2303.08774},
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {2303.08774},
    year = {2024},
    author = {OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
    title = {{GPT-4} {Technical} {Report}},
}

@inproceedings{cardon-etal-2020-presentation,
    language = {French},
    abstract = {L{'}{\'e}dition 2020 du d{\'e}fi fouille de texte (DEFT) a propos{\'e} deux t{\^a}ches autour de la similarit{\'e} textuelle et une t{\^a}che d{'}extraction d{'}information. La premi{\`e}re t{\^a}che vise {\`a} identifier le degr{\'e} de similarit{\'e} entre paires de phrases sur une {\'e}chelle de 0 (le moins similaire) {\`a} 5 (le plus similaire). Les r{\'e}sultats varient de 0,65 {\`a} 0,82 d{'}EDRM. La deuxi{\`e}me t{\^a}che consiste {\`a} d{\'e}terminer la phrase la plus proche d{'}une phrase source parmi trois phrases cibles fournies, avec des r{\'e}sultats tr{\`e}s {\'e}lev{\'e}s, variant de 0,94 {\`a} 0,99 de pr{\'e}cision. Ces deux t{\^a}ches reposent sur un corpus du domaine g{\'e}n{\'e}ral et de sant{\'e}. La troisi{\`e}me t{\^a}che propose d{'}extraire dix cat{\'e}gories d{'}informations du domaine m{\'e}dical depuis le corpus de cas cliniques de DEFT 2019. Les r{\'e}sultats varient de 0,07 {\`a} 0,66 de F-mesure globale pour la sous-t{\^a}che des pathologies et signes ou sympt{\^o}mes, et de 0,14 {\`a} 0,76 pour la sous-t{\^a}che sur huit cat{\'e}gories m{\'e}dicales. Les m{\'e}thodes utilis{\'e}es reposent sur des CRF et des r{\'e}seaux de neurones.},
    pages = {1--13},
    url = {https://aclanthology.org/2020.jeptalnrecital-deft.1},
    publisher = {ATALA et AFCP},
    address = {Nancy, France},
    year = {2020},
    month = {6},
    booktitle = {Actes de la 6e conf{\'e}rence conjointe Journ{\'e}es d'{\'E}tudes sur la Parole (JEP, 33e {\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\'e}dition), Rencontre des {\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\'E}CITAL, 22e {\'e}dition). Atelier D{\'E}fi Fouille de Textes},
    editor = {Cardon, R{\'e}mi  and
Grabar, Natalia  and
Grouin, Cyril  and
Hamon, Thierry},
    author = {Cardon, R{\'e}mi  and
Grabar, Natalia  and
Grouin, Cyril  and
Hamon, Thierry},
    title = {Pr{\'e}sentation {De} {La} {Campagne} d{'}{\'e}valuation {DEFT} {2020} {:} similarit{\'e} {Textuelle} {En} {Domaine} {Ouvert} {Et} {Extraction} d{'}information pr{\'e}cise {Dans} {Des} {Cas} {Cliniques} {(Presentation} of the {DEFT} {2020} {Challenge} {:} {Open} {Domain} {Textual} {Similarity} and {Precise} {Information} {Extraction} {From} {Clinical} {Cases} {)}},
}

@article{mantra,
    eprint = {https://academic.oup.com/jamia/article-pdf/22/5/948/34146393/ocv037.pdf},
    url = {https://doi.org/10.1093/jamia/ocv037},
    doi = {10.1093/jamia/ocv037},
    issn = {1067-5027},
    abstract = {Objective To create a multilingual gold-standard corpus for biomedical concept recognition.Materials and methods We selected text units from different parallel corpora (Medline abstract titles, drug labels, biomedical patent claims) in English, French, German, Spanish, and Dutch. Three annotators per language independently annotated the biomedical concepts, based on a subset of the Unified Medical Language System and covering a wide range of semantic groups. To reduce the annotation workload, automatically generated preannotations were provided. Individual annotations were automatically harmonized and then adjudicated, and cross-language consistency checks were carried out to arrive at the final annotations.Results The number of final annotations was 5530. Inter-annotator agreement scores indicate good agreement (median F-score 0.79), and are similar to those between individual annotators and the gold standard. The automatically generated harmonized annotation set for each language performed equally well as the best annotator for that language.Discussion The use of automatic preannotations, harmonized annotations, and parallel corpora helped to keep the manual annotation efforts manageable. The inter-annotator agreement scores provide a reference standard for gauging the performance of automatic annotation techniques.Conclusion To our knowledge, this is the first gold-standard corpus for biomedical concept recognition in languages other than English. Other distinguishing features are the wide variety of semantic groups that are being covered, and the diversity of text genres that were annotated.},
    month = {05},
    year = {2015},
    pages = {948-956},
    number = {5},
    volume = {22},
    journal = {Journal of the American Medical Informatics Association},
    title = {{A} {Multilingual} {Gold-Standard} {Corpus} for {Biomedical} {Concept} {Recognition:} the {Mantra} {GSC}},
    author = {Kors, Jan A and Clematide, Simon and Akhondi, Saber A and van Mulligen, Erik M and Rebholz-Schuhmann, Dietrich},
}

@inproceedings{morfitt,
    hal_version = {v1},
    hal_id = {hal-04125879},
    pdf = {https://hal.science/hal-04125879/file/_ARTS___TALN_RECITAL_2023__MORFITT__Multi_label_topic_classification_for_French_Biomedical_literature%20%285%29.pdf},
    keywords = {BERT ; RoBERTa ; Transformers ; Biomedical ; Clinical ; Topics ; multi-labels ; BERT ; RoBERTa ; Transformers ; Biom{\'e}dical ; Clinique ; Sp{\'e}cialit{\'e}s ; multi-labels},
    month = {jun},
    year = {2023},
    organization = {Florian Boudin},
    address = {Paris, France},
    booktitle = {30e Conf{\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN) Atelier sur l'Analyse et la Recherche de Textes Scientifiques},
    url = {https://hal.science/hal-04125879},
    author = {Labrak, Yanis and Rouvier, Micka{\"e}l and Dufour, Richard},
    title = {{MORFITT} {:} {A} {Multi-Label} {Corpus} of {French} {Scientific} {Articles} in the {Biomedical} {Domain}},
}

@misc{PxCorpus,
    url = {https://arxiv.org/abs/2207.08292},
    primaryclass = {cs.CL},
    archiveprefix = {arXiv},
    eprint = {2207.08292},
    year = {2022},
    author = {Ali Can Kocabiyikoglu and François Portet and Prudence Gibert and Hervé Blanchon and Jean-Marc Babouchkine and Gaëtan Gavazzi},
    title = {{A} {Spoken} {Drug} {Prescription} {Dataset} in {French} for {Spoken} {Language} {Understanding}},
}

@inproceedings{neveol14quaero,
    pages = {24--30},
    year = {2014},
    optseries = {BioTxtM 2014},
    booktitle = {Proc of BioTextMining Work},
    optbooktitle = {Proceedings of the Fourth Workshop on Building 
and Evaluating Ressources for Health and Biomedical 
Text Processing},
    title = {{The} {QUAERO} {French} {Medical} {Corpus:} {A} {Ressource} for {Medical} {Entity} {Recognition} and {Normalization}},
    author = {Névéol, Aurélie and Grouin, Cyril and Leixa, Jeremy 
and Rosset, Sophie and Zweigenbaum, Pierre},
}

@article{stat_sign_metho,
    numpages = {30},
    pages = {1–30},
    month = {dec},
    journal = {J. Mach. Learn. Res.},
    abstract = {While methods for comparing two learning algorithms on a single data set have been scrutinized for quite some time already, the issue of statistical tests for comparisons of more algorithms on multiple data sets, which is even more essential to typical machine learning studies, has been all but ignored. This article reviews the current practice and then theoretically and empirically examines several suitable tests. Based on that, we recommend a set of simple, yet safe and robust non-parametric tests for statistical comparisons of classifiers: the Wilcoxon signed ranks test for comparison of two classifiers and the Friedman test with the corresponding post-hoc tests for comparison of more classifiers over multiple data sets. Results of the latter can also be neatly presented with the newly introduced CD (critical difference) diagrams.},
    issn = {1532-4435},
    volume = {7},
    publisher = {JMLR.org},
    issue_date = {12/1/2006},
    year = {2006},
    title = {{Statistical} {Comparisons} of {Classifiers} {Over} {Multiple} {Data} {Sets}},
    author = {Dem\v{s}ar, Janez},
}

@article{doi:10.1080/01621459.1937.10503522,
    doi = {10.1080/01621459.1937.10503522},
    publisher = {Taylor \& Francis},
    year = {1937},
    pages = {675--701},
    number = {200},
    volume = {32},
    journal = {Journal of the American Statistical Association},
    title = {{The} {Use} of {Ranks} to {Avoid} the {Assumption} of {Normality} {Implicit} in the {Analysis} of {Variance}},
    author = {Milton Friedman},
}

@article{rainio_evaluation_2024,
    date = {2024-03-13},
    author = {Rainio, Oona and Teuho, Jarmo and Klén, Riku},
    shortjournal = {Scientific Reports},
    journaltitle = {Scientific Reports},
    number = {1},
    pages = {6086},
    abstract = {Research on different machine learning ({ML}) has become incredibly popular during the past few decades. However, for some researchers not familiar with statistics, it might be difficult to understand how to evaluate the performance of {ML} models and compare them with each other. Here, we introduce the most common evaluation metrics used for the typical supervised {ML} tasks including binary, multi-class, and multi-label classification, regression, image segmentation, object detection, and information retrieval. We explain how to choose a suitable statistical test for comparing models, how to obtain enough values of the metric for testing, and how to perform the test and interpret its results. We also present a few practical examples about comparing convolutional neural networks used to classify X-rays with different lung infections and detect cancer tumors in positron emission tomography images.},
    doi = {10.1038/s41598-024-56706-x},
    url = {https://doi.org/10.1038/s41598-024-56706-x},
    issn = {2045-2322},
    volume = {14},
    title = {{Evaluation} {Metrics} and {Statistical} {Tests} for {Machine} {Learning}},
}

@article{JMLR:v9:garcia08a,
    url = {http://jmlr.org/papers/v9/garcia08a.html},
    pages = {2677--2694},
    number = {89},
    volume = {9},
    year = {2008},
    journal = {Journal of Machine Learning Research},
    title = {{An} {Extension} on {``Statistical} {Comparisons} of {Classifiers} {Over} {Multiple} {Data} {Sets''} for {All} {Pairwise} {Comparisons}},
    author = {Salvador Garc{{\'i}}a and Francisco Herrera},
}

@article{Dietterich:98,
    year = {1998},
    volume = {10},
    url = {http://neco.mitpress.org/cgi/content/abstract/10/7/1895},
    title = {{Approximate} {Statistical} {Test} {For} {Comparing} {Supervised} {Classification} {Learning} {Algorithms}},
    timestamp = {2018-06-11T13:34:33.000+0200},
    pages = {1895--1923},
    number = {7},
    keywords = {evaluation model supervised},
    journal = {Neural Computation},
    intrahash = {e232dd87659e8dbc6b0db37d8329bca4},
    interhash = {9b8f25fcaa38ceec820aa8abc7d30646},
    biburl = {https://www.bibsonomy.org/bibtex/2e232dd87659e8dbc6b0db37d8329bca4/ans},
    author = {Dietterich, Thomas G.},
    added-at = {2018-06-11T13:34:33.000+0200},
    abstract = {This article reviews five approximate statistical tests for determining whether one learning algorithm outperforms another on a particular learning task. These tests are compared experimentally to determine their probability of incorrectly detecting a difference when no difference exists (type I error). Two widely used statistical tests are shown to have high probability of type I error in certain situations and should never be used: a test for the difference of two proportions and a paired-differences t test based on taking several random train-test splits. A third test, a paired-differences t test based on 10-fold cross-validation, exhibits somewhat elevated probability of type I error. A fourth test, McNemar's test, is shown to have low type I error. The fifth test is a new test, 5x2 cv, based on five iterations of twofold cross-validation. Experiments show that this test also has acceptable type I error. The article also measures the power (ability to detect algorithm differences when they do exist) of these tests. The cross-validated t test is the most powerful. The 5x2 cv test is shown to be slightly more powerful than McNemar's test. The choice of the best test is determined by the computational cost of running the learning algorithm. For algorithms that can be executed only once, McNemar's test is the only test with acceptable type I error. For algorithms that can be executed 10 times, the 5x2 cv test is recommended, because it is slightly more powerful and because it directly measures variation due to the choice of training set.},
}

@article{mcnemar_test,
    publisher = {Springer},
    year = {1947},
    pages = {153--157},
    number = {2},
    volume = {12},
    journal = {Psychometrika},
    title = {{Note} on the {Sampling} {Error} of the {Difference} {Between} {Correlated} {Proportions} or {Percentages}},
    author = {Quinn McNemar},
}

@article{friedman1937,
    publisher = {American Statistical Association},
    year = {1937},
    pages = {675--701},
    number = {200},
    volume = {32},
    journal = {Journal of the American Statistical Association},
    title = {{The} {Use} of {Ranks} to {Avoid} the {Assumption} of {Normality} {Implicit} in the {Analysis} of {Variance}},
    author = {Milton Friedman},
}

@article{bonferroni,
    publisher = {American Statistical Association},
    year = {1961},
    pages = {52--64},
    number = {293},
    volume = {56},
    journal = {Journal of the American Statistical Association},
    title = {{Multiple} {Comparisons} {Among} {Means}},
    author = {Olive Jean Dunn},
}

@article{tukey1949,
    publisher = {International Biometric Society},
    year = {1949},
    pages = {99--114},
    number = {2},
    volume = {5},
    journal = {Biometrics},
    title = {{Comparing} {Individual} {Means} in the {Analysis} of {Variance}},
    author = {John W. Tukey},
}

@article{example_translation,
    abstract = {Résumé
La prévalence du surpoids et de l’obésité est en augmentation dans le monde depuis plusieurs décennies, chez les hommes comme chez les femmes. En France, la prévalence du surpoids chez les adultes atteint 49 % en 2015 (54 % des hommes et 44 % des femmes), dont 17 % d’obèses. D’après la dernière évaluation réalisée par le CIRC en 2017, le surpoids et l’obésité sont des facteurs de risque établis pour 13 localisations de cancers avec un risque de cancer chez les obèses variant fortement en fonction des localisations cancéreuses. En 2015 en France, on estime que 5,4 % des cancers étaient attribuables à l’excès de poids soit 18 600 cas, dont 3400 cancers du côlon, 2600 cancers du rein, 4500 cancers du sein et 2500 cancers de l’endomètre. L’obésité est aussi associée à un moins bon pronostic pour certains cancers, en particulier les cancers du sein et du côlon. L’obésité chez les enfants et les adolescents, en augmentation dans de nombreux pays, a également été associée à une augmentation du risque de cancer à l’âge adulte. L’obésité a pour origine principale un déséquilibre de la balance énergétique et est favorisée par un régime alimentaire riche en produits transformés, viande rouge, acides gras trans et saturés, boissons et aliments sucrés et pauvres en fruits et légumes, légumineuses et céréales complètes. Les principales recommandations nationales et internationales en matière de réduction de la prévalence de l’obésité préconisent donc de pratiquer une activité physique et d’avoir une alimentation équilibrée.
Summary
In the past decades, obesity and overweight prevalence has been rising worldwide, in both men and women. In France, the prevalence of overweight in adults was 49% in 2015 (54% among men and 44% among women), including 17% of obese adults. According to the last evaluation performed by IARC in 2017, overweight and obesity are established risk factors for 13 cancer sites with risk estimates per 5kg/m2 varying largely depending on the cancer site. In 2015 in France, 5.4% of cancer cases could be attributed to excess weight, corresponding to 18,600 cases, including 3400 colon cancers, 2600 kidney cancers, 4500 breast cancers and 2500 endometrial cancers. Obesity is also related to worse prognosis for some cancers, in particular breast and colon cancers. Obesity in children and adolescents, also rising in many countries, has also been associated to an increase in adult cancer risk. A major cause of obesity is a disequilibrium in energy balance favoured by a diet rich in processed food, red meat, trans and saturated fatty acids, sweetened foods and beverages and poor in fruits and vegetables, legumes and whole grains. Main national and international recommendations to reduce the prevalence of obesity are to have a balanced diet and regular physical activity.},
    keywords = {Surpoids, Obésité, IMC, Cancer, Prévention, Overweight, Obesity, BMI, Cancer, Prevention},
    author = {Béatrice Lauby-Secretan and Laure Dossus and Claire Marant-Micallef and Mathilde His},
    url = {https://www.sciencedirect.com/science/article/pii/S0007455119302188},
    doi = {https://doi.org/10.1016/j.bulcan.2019.04.008},
    issn = {0007-4551},
    year = {2019},
    pages = {635-646},
    number = {7},
    volume = {106},
    journal = {Bulletin du Cancer},
    title = {{Obésité} {Et} {Cancer}},
}

@inproceedings{Salazar_2020,
    year = {2020},
    author = {Salazar, Julian and Liang, Davis and Nguyen, Toan Q. and Kirchhoff, Katrin},
    publisher = {Association for Computational Linguistics},
    booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
    doi = {10.18653/v1/2020.acl-main.240},
    url = {http://dx.doi.org/10.18653/v1/2020.acl-main.240},
    title = {{Masked} {Language} {Model} {Scoring}},
}

@article{nicholson2020constructing,
    publisher = {Elsevier},
    year = {2020},
    pages = {1414--1428},
    volume = {18},
    journal = {Computational and structural biotechnology journal},
    author = {Nicholson, David N and Greene, Casey S},
    title = {{Constructing} {Knowledge} {Graphs} and {Their} {Biomedical} {Applications}},
}

@article{khan2022ai,
    publisher = {Elsevier},
    year = {2022},
    pages = {1274--1284},
    number = {5},
    volume = {27},
    journal = {Drug discovery today},
    author = {Khan, Suleiman A and Tyrchan, Christian and Moreau, Yves},
    title = {{AI-based} {Language} {Models} {Powering} {Drug} {Discovery} and {Development}},
}

@article{demner2009natural,
    publisher = {Elsevier},
    year = {2009},
    pages = {760--772},
    number = {5},
    volume = {42},
    journal = {Journal of biomedical informatics},
    author = {Demner-Fushman, Dina and Chapman, Wendy W and McDonald, Clement J},
    title = {{What} {Can} {Natural} {Language} {Processing} {Do} for {Clinical} {Decision} {Support?}},
}

@article{bergman2023bert,
    publisher = {Public Library of Science},
    year = {2023},
    pages = {e0000409},
    number = {12},
    volume = {2},
    journal = {PLOS Digital Health},
    author = {Bergman, E and D{\"u}rlich, L and Arthurson, V and Sundstr{\"o}m, A and Larsson, M and Bhuiyan, S and others},
    title = {{BERT} {Based} {Natural} {Language} {Processing} for {Triage} of {Adverse} {Drug} {Reaction} {Reports} {Shows} {Close} to {Human-Level} {Performance}},
}

@inproceedings{zero-shot-translation,
    abstract = {Zero-shot translation, translating between language pairs on which a Neural Machine Translation (NMT) system has never been trained, is an emergent property when training the system in multilingual settings. However, naive training for zero-shot NMT easily fails, and is sensitive to hyper-parameter setting. The performance typically lags far behind the more conventional pivot-based approach which translates twice using a third language as a pivot. In this work, we address the degeneracy problem due to capturing spurious correlations by quantitatively analyzing the mutual information between language IDs of the source and decoded sentences. Inspired by this analysis, we propose to use two simple but effective approaches: (1) decoder pre-training; (2) back-translation. These methods show significant improvement (4 22 BLEU points) over the vanilla zero-shot translation on three challenging multilingual datasets, and achieve similar or better results than the pivot-based approach.},
    pages = {1258--1268},
    doi = {10.18653/v1/P19-1121},
    url = {https://aclanthology.org/P19-1121},
    publisher = {Association for Computational Linguistics},
    address = {Florence, Italy},
    year = {2019},
    month = {jul},
    booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
    editor = {Korhonen, Anna  and
Traum, David  and
M{\`a}rquez, Llu{\'\i}s},
    author = {Gu, Jiatao  and
Wang, Yong  and
Cho, Kyunghyun  and
Li, Victor O.K.},
    title = {{Improved} {Zero-shot} {Neural} {Machine} {Translation} via {Ignoring} {Spurious} {Correlations}},
}